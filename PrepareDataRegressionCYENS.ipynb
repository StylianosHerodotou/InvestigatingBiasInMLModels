{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PrepareDataRegressionCYENS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"DQz6vRdU-t6W"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KGBeFFfTngr"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-Gt6KstgnEC"},"source":["# %cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgTnpYmpIoNk"},"source":["!ls drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4-TMQehuN_i"},"source":["initial_df = pd.read_csv (r'/content/drive/MyDrive/CFD 3.0 Norming Data and Codebook.csv')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPhnvYuxZp0g"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7jQq8_yuOG8"},"source":["listOfUsefulColumns=['Model',\n"," 'EthnicitySelf',\n"," 'GenderSelf',\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n","#  'Suitability',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YoVfUsCuOKw"},"source":["# delete a single row by index value 0\n","df = df.drop(labels=0, axis=0)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKScPpV6uOOt"},"source":["!ls /content/drive/MyDrive/CFD/N"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRnZm18yuOW5"},"source":["data= \"/content/drive/MyDrive/CFD/N/\"\n","ldseg=np.array(os.listdir(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EhX4p8suOa6"},"source":["def renameStuff():\n","  for filename in ldseg:\n","    parts =filename.split(\"-\")\n","    newFilename= parts[1]+\"-\"+parts[2]+\".jpg\"\n","    print(newFilename)\n","    src =data+ filename\n","    dst =data+ newFilename\n","    os.rename(src, dst)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njksWB9DuOfB"},"source":["# renameStuff()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjDMmpVqz9xJ"},"source":["list(df[\"Model\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1noj6bpK1vHp"},"source":["df[\"image\"] = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttb6vciluOi_"},"source":["directory = r'/content/drive/MyDrive/CFD/N/'\n","# i=1; \n","for filename in os.listdir(directory):\n","  parts=filename.split(\".\")\n","  # print(parts)\n","  if parts[0] in list(df[\"Model\"]):\n","      # print(filename)\n","      img= cv2.imread(directory+filename)\n","      img = img[..., ::-1]\n","      # print(i)\n","      # i=i+1\n","      listWrappedImage=[img]\n","      df[\"image\"][df.index[df[\"Model\"]==parts[0]]]=listWrappedImage\n","  else:\n","      continue\n","        \n","# img1 = cv2.imread('img1.png')\n","# img2 = cv2.imread('img2.png')\n","\n","# df = pd.DataFrame()\n","# df['img'] = [img] # Wrap image in python list\n","\n","# # Add another row using the \"dictionary way\"\n","# d2 = {'img': [img2]}\n","# df2 = pd.DataFrame.from_records(d2)\n","# df.append(df2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMsumwIMf5MU"},"source":["checkPointDF=df.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YUs8ywpong-_"},"source":["# **Here is the CHECKPOINT**"]},{"cell_type":"code","metadata":{"id":"_177T-V-Wd1a"},"source":["df=checkPointDF[checkPointDF[\"image\"]!=\"\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NX2BWHb5C31F"},"source":["# import time\n","# for index in df_toSave.index:\n","#   df.at[index,'image']=df.iloc[index]['image'].flatten()\n","#   if (index%200==0):\n","#     print(index)\n","#     time.sleep(240) # Sleep for 4 min \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GA445gIwz_l8"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjWrHbpke2H1"},"source":["floatTypeColumns= [\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n","#  'Suitability',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian']\n","\n","for column in floatTypeColumns:\n","  # print(column)\n","  df[column] = df[column].astype(float)\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQBcbYMQe2Xt"},"source":["df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldRgq8C-8l1H"},"source":["def overviewOfInputData(startIndex: int, endIndex: int, data):\n","    \"\"\"\n","    The function plots some of the pictures.\n","    \n","    Arguments:\n","    startIndex: the index of the first pictue to be shown \n","    endIndex: the index of the last pictue to be shown \n","    data: this is the np array containing the pictures.\n","    \"\"\"\n","    fig = plt.figure(figsize=(20,20))\n","    for i in range(startIndex, endIndex+1):\n","        input_img = data[i]\n","        ax = fig.add_subplot(16,12,i+1)\n","        ax.imshow(input_img, cmap=plt.cm.gray)\n","        plt.xticks(np.array([]))\n","        plt.yticks(np.array([]))\n","        plt.tight_layout()\n","    plt.show()\n","\n","def showPicture(index:int, data ):\n","  \"\"\"\n","  The function plots the picture with the given index.\n","  \n","  Arguments:\n","  index: the index of the picture to be \n","  data: this is the np array containing the pictures.\n","  \"\"\"\n","  input_img = data[index] \n","  print (input_img.shape)\n","  plt.imshow(input_img)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDcvL20bgS3v"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8LJNphJvOOP"},"source":["image_column=\"image\"\n","def applyFunctionToDataset(dataset, column, function):\n","  for index in dataset.index:\n","    # try:\n","    img= function(dataset.loc[index][column]) \n","    # except: \n","    #   print(img.shape)\n","    dataset.at[index,column]=img\n","    # if (index%200==0):\n","    #   print(index)\n","    #   time.sleep(30) # Sleep for 4 min "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cev8PidDnEud"},"source":["# image= list(df_train[\"image\"])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cjw-L351rJRx"},"source":["def resizeImage(image, height=160, width=160):\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image,size=[height,width])\n","    image=np.asarray(image)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3mt5cMzU4YR"},"source":["def flip_horizonally(image):\n","  # print(image.shape)\n","  image = tf.cast(image, tf.float32)\n","  flipped = tf.image.flip_left_right(image)\n","  flipped=np.asarray(flipped)\n","  return flipped\n","# plt.imshow( flip_horizonally(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6M-I2-P3hQ2"},"source":["import cv2\n","import numpy as np\n","import random\n","def translation(image, lowrange=5, highrange=20): \n","  # Store height and width of the image\n","  height = image.shape[0]\n","  width  = image.shape[1]\n","\n","  random_height_div= random.randint(lowrange, highrange)\n","  random_width_div = random.randint(lowrange, highrange)\n","  quarter_height, quarter_width = height / random_height_div, width / random_width_div\n","\n","  T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n","    \n","  # We use warpAffine to transform\n","  # the image using the matrix, T\n","  img_translation = cv2.warpAffine(image, T, (width, height))\n","  return img_translation\n","\n","# for i in range(10):\n","#   plot = plt.figure(i)\n","#   plt.imshow( translation(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_LbsTb0A5xS"},"source":["import numpy as np\n","import cv2\n","import random\n","\n","def rotate_image(image, angle):\n","  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n","  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n","  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n","  return result\n","\n","def random_rotate_image(image, degree_range=10):\n","  # image = tf.cast(image, tf.float32)\n","  randomAngle = random.randint(-degree_range,degree_range)\n","  # print(image.shape)\n","  image =  rotate_image( image, randomAngle)\n","  return image\n","\n","# for i in range(4):\n","#   plot = plt.figure(i)\n","#   plt.imshow( random_rotate_image(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gnI-5XtiVPs"},"source":["def random_crop(image):\n","  cropped_image = tf.image.random_crop(\n","      image, size=[int(image.shape[0]-(image.shape[0]/5)),int(image.shape[1]-(image.shape[1]/5)), image.shape[2]])\n","  cropped_image = tf.image.resize(cropped_image,size=[image.shape[0], image.shape[1]])\n","\n","  cropped_image=np.asarray(cropped_image)\n","  return cropped_image\n","\n","# for i in range(10):\n","#   plot = plt.figure(i)\n","#   croppedimage=random_crop(image)\n","#   print(croppedimage.shape)\n","#   plt.imshow( croppedimage.astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r47ZDtC2PoK9"},"source":["applyFunctionToDataset(df, image_column, resizeImage )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbUTlZGGPxfX"},"source":["df[\"image\"].iloc[0].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAV9jC15gGar"},"source":["X= df[\"image\"]\n","Y= df.drop(\"image\", axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzKSqpTE9wcg"},"source":["# overviewOfInputData(0,2, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HEUfOxVloBra"},"source":["%cd /content/drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJfeIMeMpDBY"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0W8kMr2R5NY"},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.3, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KntsYMhJphKp"},"source":["df_train= y_train\n","lista=list(x_train)\n","df_train[\"image\"]= lista"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3KmMp2y_ss3"},"source":["df_train[\"augm_type\"]=\"None\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7c3CnvI-h1PX"},"source":["# df_train.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAm3SPDRxD37"},"source":["  plt.imshow( df_train[\"image\"].iloc[0].astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZzLAtN3sRoC"},"source":["currentDF=df_train.copy()\n","chechpoint=df_train.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRUPq3yvucyU"},"source":["df_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kh68ji1hk-RD"},"source":["horizonalFlipDF= currentDF.copy()\n","applyFunctionToDataset(horizonalFlipDF, image_column, flip_horizonally )\n","horizonalFlipDF[\"augm_type\"]=\"HF\"\n","plt.imshow( horizonalFlipDF[\"image\"].iloc[0].astype(\"uint8\"))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti9tGlxuyWlm"},"source":["currentDF= pd.concat([currentDF, horizonalFlipDF], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_omF9ffyVt-"},"source":["currentDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiuKndEVywxk"},"source":["rotatedDF1=currentDF.copy()\n","rotatedDF2=currentDF.copy()\n","applyFunctionToDataset(rotatedDF1, image_column, random_rotate_image )\n","applyFunctionToDataset(rotatedDF2, image_column, random_rotate_image )\n","rotatedDF1[\"augm_type\"]=\"RO\"\n","rotatedDF2[\"augm_type\"]=\"RO\"\n","\n","plt.imshow( rotatedDF1[\"image\"].iloc[0].astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DsOoC2SdzzM8"},"source":["currentDF= pd.concat([currentDF, rotatedDF1, rotatedDF2], ignore_index=True)\n","currentDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKsx4WLHuqiB"},"source":["translationDF=horizonalFlipDF.copy()\n","randomCropping=horizonalFlipDF.copy()\n","\n","translationDF_rotated=currentDF.copy()\n","randomCropping_rotated=currentDF.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKnQMPhH0psb"},"source":["applyFunctionToDataset(translationDF, image_column, translation )\n","applyFunctionToDataset(randomCropping, image_column, random_crop )\n","\n","applyFunctionToDataset(translationDF_rotated, image_column, translation )\n","applyFunctionToDataset(randomCropping_rotated, image_column, random_crop )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CobdHSRBBcP"},"source":["translationDF[\"augm_type\"]=translationDF[\"augm_type\"]+ \"-TR\"\n","randomCropping[\"augm_type\"]=randomCropping[\"augm_type\"]+ \"-RC\"\n","translationDF_rotated[\"augm_type\"]=translationDF_rotated[\"augm_type\"]+ \"-TR\"\n","randomCropping_rotated[\"augm_type\"]=randomCropping_rotated[\"augm_type\"]+ \"-RC\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMJCvWGJ0pze"},"source":["currentDF= pd.concat([currentDF, translationDF, randomCropping, translationDF_rotated, randomCropping_rotated], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvyC4SGC1X4s"},"source":["def overviewOfInputData(startIndex: int, endIndex: int, dataframe, targetcolumn=\"image\"):\n","    \"\"\"\n","    The function plots some of the pictures.\n","    \n","    Arguments:\n","    startIndex: the index of the first pictue to be shown \n","    endIndex: the index of the last pictue to be shown \n","    data: this is the np array containing the pictures.\n","    \"\"\"\n","    fig = plt.figure(figsize=(20,20))\n","    for i in range(startIndex, endIndex+1):\n","        index= random.randint(0, dataframe.shape[0])\n","        input_img = dataframe[\"image\"].iloc[index]\n","        ax = fig.add_subplot(16,12,i+1)\n","        ax.imshow(input_img.astype(\"uint8\"))\n","        plt.xticks(np.array([]))\n","        plt.yticks(np.array([]))\n","        plt.tight_layout()\n","    plt.show()\n","\n","def showPicture(index:int, data ):\n","  \"\"\"\n","  The function plots the picture with the given index.\n","  \n","  Arguments:\n","  index: the index of the picture to be \n","  data: this is the np array containing the pictures.\n","  \"\"\"\n","  input_img = data[index] \n","  print (input_img.shape)\n","  plt.imshow(input_img)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKLC5zvb1X4u"},"source":["overviewOfInputData(0,35, currentDF)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9R8mids2Yc5"},"source":["targetcolumn=\"Trustworthy\"\n","image_column=\"image\"\n","augm_column=\"augm_type\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh1AQpwj1tBf"},"source":["x_train_final= list(currentDF[image_column])\n","y_train_final= list(currentDF[targetcolumn])\n","augment_type= list(currentDF[augm_column])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UPjAf4wFedR"},"source":["len(x_train_final)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bL_6j0RqCy5Y"},"source":["x_test= list(x_test)\n","y_test= list(y_test[targetcolumn])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZd3ZVLVDQPL"},"source":["len(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K31_fSgCDL4X"},"source":["len(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdpJh6PIDWZy"},"source":["y_test[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQeAvBuT2hzm"},"source":["# print(x_train_final.shape)\n","# y_train_final.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rm9iBzMo2kGp"},"source":["y_train_final[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSkFBrnMFqHP"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAkr4yYNCEL2"},"source":["!rm -rf TrustworthyRegression\n","!rm -rf TrustworthyRegression/Training\n","!rm -rf TrustworthyRegression/Test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-L8GyZ6CLiW"},"source":["!mkdir TrustworthyRegression\n","!mkdir TrustworthyRegression/Training\n","!mkdir TrustworthyRegression/Test\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM7zrWoXAcUN"},"source":["%cd TrustworthyRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDN1A6HyAcZ5"},"source":["!ls\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_zVyLxQGRIl"},"source":["posaEkamaSave=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQY1F9kdALq2"},"source":["from PIL import Image\n","def saveDataset(images, labels, folderName, augment_type=None):\n","  for number,image in enumerate(images):\n","    aug_type=\"None\"\n","    if (augment_type!=None):\n","      aug_type= augment_type[number]\n","    \n","    imageName=folderName+\"/image\"+str(number)+\"kostis_\"+aug_type+\"_\"+str(labels[number])+\".jpeg\"\n","    # image=image.reshape(image.shape[0],image.shape[1], )\n","    image = (((image - image.min()) / (image.max() - image.min())) * 255.9).astype(np.uint8)\n","    im = Image.fromarray(image)\n","    im.save(imageName)\n","    posaEkamaSave=number"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jU3SEaSqBIKo"},"source":["saveDataset(x_train_final,y_train_final, folderName= \"Training\", augment_type=augment_type)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8M5N0afD0-j"},"source":["# listOfAllAugTypes=[\"HF\", \"RO\",\"TR\", \"RC\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EY31_AJ_GZqJ"},"source":["posaEkamaSave"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aONB8lh0DuF4"},"source":["saveDataset(x_test,y_test, folderName= \"Test\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hR9hSBK2vQn3"},"source":["# **Save FR images**"]},{"cell_type":"code","metadata":{"id":"1SVZHVUJqw48"},"source":["!pip install deepface"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fySUqCnGTvQk"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"46ROZyYnTvQv"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ct8USyHdHHbQ"},"source":["numberOftrainingPictures= !ls /content/drive/MyDrive/TrustworthyRegression/Training | wc -l\n","numberOfTestPictures= !ls /content/drive/MyDrive/TrustworthyRegression/Test | wc -l\n","\n","numberOftrainingPictures= int(numberOftrainingPictures[0])\n","numberOfTestPictures= int(numberOfTestPictures[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98xDDKS9HSLW"},"source":["print(numberOftrainingPictures)\n","print(numberOfTestPictures)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6OZC4qSQ17K"},"source":["base_directory = r\"/content/drive/MyDrive/TrustworthyRegression/\"\n","\n","def readData(numberOfPictures,dirName):\n","  sizeOfInput=(numberOfPictures,160,160,3)\n","  x= np.empty(shape=sizeOfInput,dtype=np.uint8)\n","  y= np.empty(shape=(numberOfPictures,))\n","  aug= list()\n","\n","  directory=base_directory+ dirName+ \"/\"\n","  print(directory)\n","  for index, filename in enumerate(os.listdir(directory)):\n","\n","    img= cv2.imread(directory+filename)\n","    try:\n","      img = img[..., ::-1]\n","      img=img.astype(\"uint8\")\n","    except Exception as e: \n","      print(\"FUUUUCK\\n\"+ filename )\n","      print(e)\n","      continue\n","\n","\n","    rest= filename.split(\"kostis_\")[1]\n","    rest=rest.split(\"_\")\n","    aug_type=rest[0]\n","\n","    label=rest[1] \n","    label= float(label.split(\".jp\")[0])\n","\n","    x[index]=img\n","    y[index]=label\n","    aug.append(aug_type)\n","  \n","  return x,y,aug"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnfZ90DwRviT"},"source":["x_train_all, y_train_all, aug_train=readData(numberOfPictures=numberOftrainingPictures\n","                                             ,dirName=\"Training\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbeVM-33YvNm"},"source":["x_test, y_test, aug_test=readData(numberOfPictures=numberOfTestPictures\n","                                             ,dirName=\"Test\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kz8HXx4NaFiV"},"source":["def showUnique(list1):\n","    x = np.array(list1)\n","    print(np.unique(x))\n","\n","from collections import Counter\n","\n","\n","def getImagesDividedByAugType(x, y, aug_method):\n","  showUnique(aug_method)\n","  # print(\"this is a images from the initial read\")\n","  # plt.imshow(x[-1])\n","  # plt.show()\n","  count_of_items= Counter(aug_method)\n","  print(count_of_items)\n","  ImagesDividedByAugType={}\n","  for key, value in count_of_items.items():\n","    numberOfPictures=value\n","    sizeOfInput=(numberOfPictures,160,160,3)\n","    # print(sizeOfInput)\n","\n","    current_x= np.empty(shape=sizeOfInput,dtype=np.uint8)\n","    current_y= np.empty(shape=(numberOfPictures,))\n","    current_aug_type=list()\n","    counter=0;\n","    ImagesDividedByAugType[key]={\"x\":current_x,\"y\":current_y,\"aug_type\": current_aug_type,\"counter\":counter}\n","  \n","  for index, picture in enumerate(x):\n","    dic= ImagesDividedByAugType[aug_method[index]]\n","    dic[\"x\"][dic[\"counter\"]]=picture\n","    # plt.imshow(picture)\n","    # plt.show()\n","    # plt.imshow(dic[\"x\"][dic[\"counter\"]])\n","    # plt.show()\n","    # break;\n","    dic[\"y\"][dic[\"counter\"]]=y[index]\n","    dic[\"aug_type\"].append(aug_method[index])\n","    dic[\"counter\"]=dic[\"counter\"]+1\n","\n","    ImagesDividedByAugType[aug_method[index]]=dic\n","  return ImagesDividedByAugType\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAt5xQ-FaoF2"},"source":["len(x_train_all)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-X2RstAKaLEJ"},"source":["imagesDividedByAugType_test=getImagesDividedByAugType(x=x_test, y=y_test, aug_method=aug_test)\n","imagesDividedByAugType_train=getImagesDividedByAugType(x=x_train_all, y=y_train_all, aug_method=aug_train)\n","\n","\n","# plt.imshow(imagesDividedByAugType_train[\"None\"][\"x\"][1])\n","# plt.show()\n","# print(imagesDividedByAugType[\"None\"][\"aug_type\"][-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVvvUPwRWYyD"},"source":["import time\n","from os import path\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import pickle\n","\n","from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID, DlibWrapper, ArcFace, Boosting\n","from deepface.commons import functions, realtime, distance as dst\n","from keras.preprocessing import image as image_keras_preprocessing\n","\n","#################\n","\n","def postProcesssing(img, grayscale=False,target_size=(160,160)):\n","  #post-processing\n","  if grayscale == True:\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","  img = cv2.resize(img, target_size)\n","  #TODO: resize causes transformation on base image, you should add black pixels to rezie it to target_size\n","\n","  img_pixels = image_keras_preprocessing.img_to_array(img)\n","  img_pixels = np.expand_dims(img_pixels, axis = 0)\n","  img_pixels /= 255 #normalize input in [0, 1]\n","  return img_pixels\n","\n","\n","def getFaceImages(images, listWithFaceDetectors=[\"ssd\", \"opencv\",\"mtcnn\",\"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True):\n","  #detect face in all images\n","  FRimages=list()\n","  for image in images: \n","    managed_to_find_face=False\n","    for detector_backend in listWithFaceDetectors:\n","      try:\n","          img, region = functions.detect_face(img = image, detector_backend = detector_backend, grayscale = grayscale, enforce_detection = enforce_detection, align = align)\n","          #--------------------------\n","          if img.shape[0] == 0 or img.shape[1] == 0:\n","            if enforce_detection == True:\n","              raise ValueError(\"Detected face shape is \", img.shape,\". Consider to set enforce_detection argument to False.\")\n","            else: #restore base image\n","              img = base_img.copy()\n","          #--------------------------\n","\n","        #   img = functions.preprocess_face(img = image\n","        # , target_size=(input_shape_y, input_shape_x)\n","        # , enforce_detection = enforce_detection\n","        # , detector_backend = detector_backend\n","        # , align = align)\n","          managed_to_find_face=True\n","          img= resizeImage(image=img).astype(\"uint8\")\n","          FRimages.append(img)\n","          break;\n","      except ValueError: \n","        continue\n","    if(managed_to_find_face==False):\n","      print(\"I COUNT NOT FIND THE FACE!!!!!\")\n","      plt.imshow(image)\n","  return FRimages\n","\n","def getSizeOfEmbedings(tempImage,model_list):\n","  sizeOfFinalinput=0;\n","  for model in model_list:\n","    input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","    img= postProcesssing(tempImage, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","    curentEmbedings = model.predict(img)[0].tolist()\n","    sizeOfFinalinput= sizeOfFinalinput+ len(curentEmbedings)\n","  return sizeOfFinalinput\n","\n","def getEmbedings(FRimages,model_list, sizeOfFinalInput):\n","  inputSize=(len(FRimages), sizeOfFinalInput)\n","  embedings=np.empty(inputSize)\n","  for index, image in enumerate(FRimages):\n","    image_embedgins= list()\n","    for model in model_list:\n","      try:\n","        input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","        img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","        curentEmbedings = model.predict(img)[0].tolist()\n","        image_embedgins.extend(curentEmbedings)\n","      except:\n","        print(\"i couldnt get embedings\")\n","        plt.imshow(image)\n","    npEmbedings=np.asarray(image_embedgins)\n","    embedings[index]=npEmbedings\n","  return embedings\n","\n","\n","def myRepresent(images,model_list , listWithFaceDetectors=[\"ssd\", \"opencv\",\"mtcnn\",\"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True):\n","  \"\"\"\n","  This function represents facial images as vectors.\n","  Parameters:\n","    img_path: exact image path, numpy array or based64 encoded images could be passed.\n","    model_name (string): VGG-Face, Facenet, OpenFace, DeepFace, DeepID, Dlib, ArcFace.\n","    model: Built deepface model. A face recognition model is built every call of verify function. You can pass pre-built face recognition model optionally if you will call verify function several times. Consider to pass model if you are going to call represent function in a for loop.\n","      model = DeepFace.build_model('VGG-Face')\n","    enforce_detection (boolean): If any face could not be detected in an image, then verify function will return exception. Set this to False not to have this exception. This might be convenient for low resolution images.\n","    detector_backend (string): set face detector backend as retinaface, mtcnn, opencv, ssd or dlib\n","  Returns:\n","    Represent function returns a multidimensional vector. The number of dimensions is changing based on the reference model. E.g. FaceNet returns 128 dimensional vector; VGG-Face returns 2622 dimensional vector.\n","  \"\"\"\n","  \n","  #detect face in all images\n","  FRimages=getFaceImages(images=images, listWithFaceDetectors=listWithFaceDetectors, grayscale=grayscale, enforce_detection = enforce_detection, align = align)\n","\n","\n","  tempImage=FRimages[0]\n","  sizeOfFinalinput=getSizeOfEmbedings(tempImage,model_list)\n","  print(\"sizeOfFinalinput \"+str(sizeOfFinalinput) )\n","\n","  embedings=getEmbedings(FRimages,model_list, sizeOfFinalInput=sizeOfFinalinput)\n","  return embedings\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC2b6yhBcVEx"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aue-BvuQcWaq"},"source":["%cd /content/drive/My Drive/TrustworthyRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZrX0aJTog0z"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Od9SpKZdqqb2"},"source":["!rm -rf FaceRecognisionImages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmsyoX9Gqqb2"},"source":["!mkdir FaceRecognisionImages\n","\n","!mkdir FaceRecognisionImages/Training\n","!mkdir FaceRecognisionImages/Training/HF\n","!mkdir FaceRecognisionImages/Training/None\n","!mkdir FaceRecognisionImages/Training/RO\n","!mkdir FaceRecognisionImages/Training/RO-RC\n","!mkdir FaceRecognisionImages/Training/HF-RC\n","!mkdir FaceRecognisionImages/Training/RO-TR\n","!mkdir FaceRecognisionImages/Training/None-RC\n","!mkdir FaceRecognisionImages/Training/None-TR\n","!mkdir FaceRecognisionImages/Training/HF-TR\n","\n","\n","\n","!mkdir FaceRecognisionImages/Test\n","!mkdir FaceRecognisionImages/Test/HF\n","!mkdir FaceRecognisionImages/Test/None\n","!mkdir FaceRecognisionImages/Test/RO\n","!mkdir FaceRecognisionImages/Test/RO-RC\n","!mkdir FaceRecognisionImages/Test/HF-RC\n","!mkdir FaceRecognisionImages/Test/RO-TR\n","!mkdir FaceRecognisionImages/Test/None-RC\n","!mkdir FaceRecognisionImages/Test/None-TR\n","!mkdir FaceRecognisionImages/Test/HF-TR\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQ164BwqchZ5"},"source":["%cd FaceRecognisionImages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAt7KLuTqqb3"},"source":["from PIL import Image\n","def saveFRimages(FRimages, labels, folderName, augment_type=None):\n","  for number,image in enumerate(FRimages):\n","    aug_type=\"None\"\n","    if (augment_type!=None):\n","      aug_type= augment_type[number]\n","    imageName=folderName+\"/FRimage\"+str(number)+\"kostis_\"+aug_type+\"_\"+str(labels[number])+\".jpeg\"\n","    # image=image.reshape(image.shape[0],image.shape[1], )\n","    image = (((image - image.min()) / (image.max() - image.min())) * 255.9).astype(np.uint8)\n","    im = Image.fromarray(image)\n","    im.save(imageName)\n","    # print(\"saved \"+imageName)\n","    posaEkamaSave=number\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwHlL99FcNSu"},"source":["def saveAccordingToAugType(imagesDividedByAugType, base_folder):\n","  for key, dic in imagesDividedByAugType.items():\n","    # dic=={\"x\":x,\"y\":y,\"aug_type\": aug_type,\"counter\":counter}\n","    FRimages= getFaceImages(images=dic[\"x\"], listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True)\n","    folderName= base_folder+\"/\"+key\n","    saveFRimages(FRimages,dic[\"y\"], folderName= folderName , augment_type=dic[\"aug_type\"])\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbTxLRrIeIKX"},"source":["imagesDividedByAugType_test=getImagesDividedByAugType(x=x_test, y=y_test, aug_method=aug_test)\n","imagesDividedByAugType_train=getImagesDividedByAugType(x=x_train_all, y=y_train_all, aug_method=aug_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibztPrh9oXHX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Y9xvasxeC8z"},"source":["saveAccordingToAugType(imagesDividedByAugType_train, base_folder=\"Training\")\n","saveAccordingToAugType(imagesDividedByAugType_test, base_folder=\"Test\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jju8wy5wa9wq"},"source":["# FRimages= getFaceImages(images=x_train_all, listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmrPefXxpaRH"},"source":["# FRimages_test= getFaceImages(images=x_test, listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4sTNLnNjomz0"},"source":["# plt.imshow(FRimages[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LLelSkvY5Dw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mIyPCT-b1Jm"},"source":["% cd /content/drive/MyDrive/AttracivenessRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ac0JOR5TesGf"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUAJoRipllek"},"source":["%cd FaceRecognisionImages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0FtSFQMltXN"},"source":["ls "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORzC1CMGoi7v"},"source":["posaEkamaSave=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E384yMGiqqb3"},"source":["saveFRimages(FRimages,y_train, folderName= \"Training\", augment_type=aug_type_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2w0-rx3p9JY"},"source":["saveFRimages(FRimages_test,y_test, folderName= \"Test\", augment_type=aug_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQYq01dvqK-h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNJkUmfYqqb3"},"source":["numberOftrainingPictures= !ls /content/drive/MyDrive/AttracivenessRegression/FaceRecognisionImages/Training | wc -l\n","numberOfTestPictures= !ls /content/drive/MyDrive/AttracivenessRegression/FaceRecognisionImages/Test | wc -l\n","\n","numberOftrainingPictures= int(numberOftrainingPictures[0])\n","numberOfTestPictures= int(numberOfTestPictures[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImONHBxcqahC"},"source":[""]},{"cell_type":"code","metadata":{"id":"fcA9B5BTrjpj"},"source":["import os\n","\n","def findNumberOfItemsInDirectory(directoryPath):\n","\n","  totalFiles = 0\n","  totalDir = 0\n","\n","  for base, dirs, files in os.walk(directoryPath):\n","      print('Searching in : ',base)\n","      for Files in files:\n","          totalFiles += 1\n","\n","  return totalFiles\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7Sv8Xu8qlIx"},"source":["def readDataFromSingleFolder(dirPath):\n","  numberOfPictures= findNumberOfItemsInDirectory(dirPath)\n","  sizeOfInput=(numberOfPictures,160,160,3)\n","  x= np.empty(shape=sizeOfInput,dtype=np.uint8)\n","  y= np.empty(shape=(numberOfPictures,))\n","  aug= list()\n","\n","  directory=dirPath+ \"/\"\n","  print(directory)\n","  for index, filename in enumerate(os.listdir(directory)):\n","\n","    img= cv2.imread(directory+filename)\n","    try:\n","      img = img[..., ::-1]\n","      img=img.astype(\"uint8\")\n","    except Exception as e: \n","      print(\"FUUUUCK\\n\"+ filename )\n","      print(e)\n","      continue\n","\n","\n","    rest= filename.split(\"kostis_\")[1]\n","    rest=rest.split(\"_\")\n","    aug_type=rest[0]\n","\n","    label=rest[1] \n","    label= float(label.split(\".jp\")[0])\n","\n","    x[index]=img\n","    y[index]=label\n","    aug.append(aug_type)\n","  \n","  return x,y,aug"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqwe6wkqqqb4"},"source":["base_directory = r\"/content/drive/MyDrive/AttracivenessRegression/FaceRecognisionImages/\"\n","def readFRImages(listOfDesiredAugmentation, directory_plug_in=\"\"):\n","  totalX=[]\n","  totalY=[]\n","\n","  for directory in listOfDesiredAugmentation:\n","    x,y,aug= readDataFromSingleFolder(base_directory+directory_plug_in+ directory)\n","    totalX.append(x)\n","    totalY.append(y)\n","\n","  images= np.concatenate(totalX, axis=0)\n","  labels= np.concatenate(totalY, axis=0)\n","\n","  return images,labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OV9YqsRntSfe"},"source":["listOfDesiredAugmentation=['HF', 'None', 'RO', 'RO-RC', 'HF-RC', 'RO-TR', 'None-RC', 'None-TR', 'HF-TR']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EOkTchFtEWl"},"source":["training_images, training_labels=readFRImages(listOfDesiredAugmentation=listOfDesiredAugmentation, directory_plug_in=\"Training/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VS4gt2uuH46"},"source":["testing_images, testing_labels=readFRImages(listOfDesiredAugmentation=listOfDesiredAugmentation, directory_plug_in=\"Test/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRKfQjS6uLSf"},"source":["training_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvkHkGYLuPPt"},"source":["testing_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amNJ85vLveXf"},"source":["# **Save Face Encodings Acording to Model- Augmentation Type**\n","\n"]},{"cell_type":"code","metadata":{"id":"g-411nfRviza"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Njd9h8OxPhV"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHt5Y4reLL3T"},"source":["!pip install deepface"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMdOI8Ly3pQX"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lngeadf3pQX"},"source":["import matplotlib.pyplot as plt\n","def plot_accuracy(history):\n","  acc = history.history['accuracy']\n","  val_acc = history.history['val_accuracy']\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  epochs = range(len(acc))\n","\n","  plt.plot(epochs, acc, 'r', label='Training accuracy')\n","  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","  plt.title('Training and validation accuracy')\n","  plt.legend(loc=0)\n","  plt.figure()\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrsoxmKJmhg8"},"source":["import os\n","from pathlib import Path\n","import gdown\n","from functools import partial\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras import backend as K\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Input, concatenate\n","from tensorflow.keras.layers import Dense, Activation, Lambda, Flatten, BatchNormalization\n","from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.models import load_model\n","tf_version = int(tf.__version__.split(\".\")[0])\n","from tensorflow.python.keras import backend\n","from tensorflow.python.keras.engine import training\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.python.keras.utils import layer_utils\n","from tensorflow.python.lib.io import file_io\n","import tensorflow\n","import zipfile\n","from tensorflow.keras.layers import Convolution2D, LocallyConnected2D, Add, Dropout\n","from tensorflow.keras.layers import Concatenate\n","\n","\n","if tf_version == 1:\n","\tfrom keras.models import Model, Sequential\n","\tfrom keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n","else:\n","\tfrom tensorflow import keras\n","\tfrom tensorflow.keras.models import Model, Sequential\n","\tfrom tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n","\t\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxs0aYyRSFdY"},"source":["\n","\n","def scaling(x, scale):\n","\treturn x * scale\n","\n","def InceptionResNetV2():\n","\t\n","\tinputs = Input(shape=(160, 160, 3))\n","\tx = Conv2D(32, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_1a_3x3') (inputs)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_1a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_1a_3x3_Activation')(x)\n","\tx = Conv2D(32, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_2a_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_2a_3x3_Activation')(x)\n","\tx = Conv2D(64, 3, strides=1, padding='same', use_bias=False, name= 'Conv2d_2b_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2b_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_2b_3x3_Activation')(x)\n","\tx = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n","\tx = Conv2D(80, 1, strides=1, padding='valid', use_bias=False, name= 'Conv2d_3b_1x1') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_3b_1x1_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_3b_1x1_Activation')(x)\n","\tx = Conv2D(192, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_4a_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_4a_3x3_Activation')(x)\n","\tx = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_4b_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4b_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_4b_3x3_Activation')(x)\n","\t\n","\t# 5x Block35 (Inception-ResNet-A block):\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_1_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_2_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_3_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_4_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_5_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_5_Activation')(x)\n","\n","\t# Mixed 6a (Reduction-A block):\n","\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_0_Conv2d_1a_3x3') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_1a_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n","\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_6a_Branch_2_MaxPool_1a_3x3')(x)\n","\tbranches = [branch_0, branch_1, branch_pool]\n","\tx = Concatenate(axis=3, name='Mixed_6a')(branches)\n","\n","\t# 10x Block17 (Inception-ResNet-B block):\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_1_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_2_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_3_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_4_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_5_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_5_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_6_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_6_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_6_Activation')(x)\t\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_7_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_7_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_7_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_7_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_8_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_8_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_8_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_8_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_9_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_9_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_9_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_9_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_10_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_10_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_10_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_10_Activation')(x)\n","\n","\t# Mixed 7a (Reduction-B block): 8 x 8 x 2080\t\n","\tbranch_0 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_0a_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation')(branch_0)\n","\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_1a_3x3') (branch_0)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n","\tbranch_1 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_1a_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(256, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_1a_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation')(branch_2)\n","\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_7a_Branch_3_MaxPool_1a_3x3')(x)\n","\tbranches = [branch_0, branch_1, branch_2, branch_pool]\n","\tx = Concatenate(axis=3, name='Mixed_7a')(branches)\n","\n","\t# 5x Block8 (Inception-ResNet-C block):\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_1_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_2_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_3_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_4_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_5_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_5_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_6_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_6_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 1})(up)\n","\tx = add([x, up])\n","\t\n","\t# Classification block\n","\tx = GlobalAveragePooling2D(name='AvgPool')(x)\n","\tx = Dropout(1.0 - 0.8, name='Dropout')(x)\n","\t# Bottleneck\n","\tx = Dense(128, use_bias=False, name='Bottleneck')(x)\n","\tx = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name='Bottleneck_BatchNorm')(x)\n","\n","\t# Create model\n","\tmodel = Model(inputs, x, name='inception_resnet_v1')\n","\n","\treturn model\n","\n","\n","\n","\n","#---------------------------------------\n","\n","def vggbaseModel():\n","\tmodel = Sequential()\n","\tmodel.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n","\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(Convolution2D(4096, (7, 7), activation='relu'))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Convolution2D(4096, (1, 1), activation='relu'))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Convolution2D(2622, (1, 1)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Activation('softmax'))\n","\t\n","\treturn model\n","\n","\n","\n","#---------------------------------------\n","\n","def openFaceModel():\n","  myInput = Input(shape=(96, 96, 3))\n","\n","  x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n","  x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n","  x = Activation('relu')(x)\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = MaxPooling2D(pool_size=3, strides=2)(x)\n","  x = Lambda(lambda x: tf.nn.lrn(x, alpha=1e-4, beta=0.75), name='lrn_1')(x)\n","  x = Conv2D(64, (1, 1), name='conv2')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n","  x = Activation('relu')(x)\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = Conv2D(192, (3, 3), name='conv3')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n","  x = Activation('relu')(x)\n","  x = Lambda(lambda x: tf.nn.lrn(x, alpha=1e-4, beta=0.75), name='lrn_2')(x) #x is equal added\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = MaxPooling2D(pool_size=3, strides=2)(x)\n","\n","  # Inception3a\n","  inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n","  inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n","  inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n","  inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n","  inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n","  inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n","  inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n","\n","  inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n","  inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n","  inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n","  inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n","  inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n","  inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n","  inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n","\n","  inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n","  inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n","  inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n","  inception_3a_pool = Activation('relu')(inception_3a_pool)\n","  inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n","\n","  inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n","  inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n","  inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n","\n","  inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n","\n","  # Inception3b\n","  inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n","  inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n","  inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n","  inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n","  inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n","  inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n","  inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n","\n","  inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n","  inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n","  inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n","  inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n","  inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n","  inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n","  inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n","\n","  inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n","  inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n","  inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n","  inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n","  inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n","  inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n","  inception_3b_pool = Activation('relu')(inception_3b_pool)\n","  inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n","\n","  inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n","  inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n","  inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n","\n","  inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n","\n","  # Inception3c\n","  inception_3c_3x3 = Conv2D(128, (1, 1), strides=(1, 1), name='inception_3c_3x3_conv1')(inception_3b)\n","  inception_3c_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_3x3_bn1')(inception_3c_3x3)\n","  inception_3c_3x3 = Activation('relu')(inception_3c_3x3)\n","  inception_3c_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3c_3x3)\n","  inception_3c_3x3 = Conv2D(256, (3, 3), strides=(2, 2), name='inception_3c_3x3_conv'+'2')(inception_3c_3x3)\n","  inception_3c_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_3x3_bn'+'2')(inception_3c_3x3)\n","  inception_3c_3x3 = Activation('relu')(inception_3c_3x3)\n","\n","  inception_3c_5x5 = Conv2D(32, (1, 1), strides=(1, 1), name='inception_3c_5x5_conv1')(inception_3b)\n","  inception_3c_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_5x5_bn1')(inception_3c_5x5)\n","  inception_3c_5x5 = Activation('relu')(inception_3c_5x5)\n","  inception_3c_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3c_5x5)\n","  inception_3c_5x5 = Conv2D(64, (5, 5), strides=(2, 2), name='inception_3c_5x5_conv'+'2')(inception_3c_5x5)\n","  inception_3c_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_5x5_bn'+'2')(inception_3c_5x5)\n","  inception_3c_5x5 = Activation('relu')(inception_3c_5x5)\n","\n","  inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n","  inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n","\n","  inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n","\n","  #inception 4a\n","  inception_4a_3x3 = Conv2D(96, (1, 1), strides=(1, 1), name='inception_4a_3x3_conv'+'1')(inception_3c)\n","  inception_4a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_3x3_bn'+'1')(inception_4a_3x3)\n","  inception_4a_3x3 = Activation('relu')(inception_4a_3x3)\n","  inception_4a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3)\n","  inception_4a_3x3 = Conv2D(192, (3, 3), strides=(1, 1), name='inception_4a_3x3_conv'+'2')(inception_4a_3x3)\n","  inception_4a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_3x3_bn'+'2')(inception_4a_3x3)\n","  inception_4a_3x3 = Activation('relu')(inception_4a_3x3)\n","\n","  inception_4a_5x5 = Conv2D(32, (1,1), strides=(1,1), name='inception_4a_5x5_conv1')(inception_3c)\n","  inception_4a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_5x5_bn1')(inception_4a_5x5)\n","  inception_4a_5x5 = Activation('relu')(inception_4a_5x5)\n","  inception_4a_5x5 = ZeroPadding2D(padding=(2,2))(inception_4a_5x5)\n","  inception_4a_5x5 = Conv2D(64, (5,5), strides=(1,1), name='inception_4a_5x5_conv'+'2')(inception_4a_5x5)\n","  inception_4a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_5x5_bn'+'2')(inception_4a_5x5)\n","  inception_4a_5x5 = Activation('relu')(inception_4a_5x5)\n","\n","  inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n","  inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n","  inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n","  inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n","\n","  inception_4a_pool = Conv2D(128, (1,1), strides=(1,1), name='inception_4a_pool_conv'+'')(inception_4a_pool)\n","  inception_4a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_pool_bn'+'')(inception_4a_pool)\n","  inception_4a_pool = Activation('relu')(inception_4a_pool)\n","  inception_4a_pool = ZeroPadding2D(padding=(2, 2))(inception_4a_pool)\n","\n","  inception_4a_1x1 = Conv2D(256, (1, 1), strides=(1, 1), name='inception_4a_1x1_conv'+'')(inception_3c)\n","  inception_4a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_1x1_bn'+'')(inception_4a_1x1)\n","  inception_4a_1x1 = Activation('relu')(inception_4a_1x1)\n","\n","  inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n","\n","  #inception4e\n","  inception_4e_3x3 = Conv2D(160, (1,1), strides=(1,1), name='inception_4e_3x3_conv'+'1')(inception_4a)\n","  inception_4e_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_3x3_bn'+'1')(inception_4e_3x3)\n","  inception_4e_3x3 = Activation('relu')(inception_4e_3x3)\n","  inception_4e_3x3 = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3)\n","  inception_4e_3x3 = Conv2D(256, (3,3), strides=(2,2), name='inception_4e_3x3_conv'+'2')(inception_4e_3x3)\n","  inception_4e_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_3x3_bn'+'2')(inception_4e_3x3)\n","  inception_4e_3x3 = Activation('relu')(inception_4e_3x3)\n","\n","  inception_4e_5x5 = Conv2D(64, (1,1), strides=(1,1), name='inception_4e_5x5_conv'+'1')(inception_4a)\n","  inception_4e_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_5x5_bn'+'1')(inception_4e_5x5)\n","  inception_4e_5x5 = Activation('relu')(inception_4e_5x5)\n","  inception_4e_5x5 = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5)\n","  inception_4e_5x5 = Conv2D(128, (5,5), strides=(2,2), name='inception_4e_5x5_conv'+'2')(inception_4e_5x5)\n","  inception_4e_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_5x5_bn'+'2')(inception_4e_5x5)\n","  inception_4e_5x5 = Activation('relu')(inception_4e_5x5)\n","\n","  inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n","  inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n","\n","  inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n","\n","  #inception5a\n","  inception_5a_3x3 = Conv2D(96, (1,1), strides=(1,1), name='inception_5a_3x3_conv'+'1')(inception_4e)\n","  inception_5a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_3x3_bn'+'1')(inception_5a_3x3)\n","  inception_5a_3x3 = Activation('relu')(inception_5a_3x3)\n","  inception_5a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3)\n","  inception_5a_3x3 = Conv2D(384, (3,3), strides=(1,1), name='inception_5a_3x3_conv'+'2')(inception_5a_3x3)\n","  inception_5a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_3x3_bn'+'2')(inception_5a_3x3)\n","  inception_5a_3x3 = Activation('relu')(inception_5a_3x3)\n","\n","  inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n","  inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n","  inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n","  inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n","\n","  inception_5a_pool = Conv2D(96, (1,1), strides=(1,1), name='inception_5a_pool_conv'+'')(inception_5a_pool)\n","  inception_5a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_pool_bn'+'')(inception_5a_pool)\n","  inception_5a_pool = Activation('relu')(inception_5a_pool)\n","  inception_5a_pool = ZeroPadding2D(padding=(1,1))(inception_5a_pool)\n","\n","  inception_5a_1x1 = Conv2D(256, (1,1), strides=(1,1), name='inception_5a_1x1_conv'+'')(inception_4e)\n","  inception_5a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_1x1_bn'+'')(inception_5a_1x1)\n","  inception_5a_1x1 = Activation('relu')(inception_5a_1x1)\n","\n","  inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n","\n","  #inception_5b\n","  inception_5b_3x3 = Conv2D(96, (1,1), strides=(1,1), name='inception_5b_3x3_conv'+'1')(inception_5a)\n","  inception_5b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_3x3_bn'+'1')(inception_5b_3x3)\n","  inception_5b_3x3 = Activation('relu')(inception_5b_3x3)\n","  inception_5b_3x3 = ZeroPadding2D(padding=(1,1))(inception_5b_3x3)\n","  inception_5b_3x3 = Conv2D(384, (3,3), strides=(1,1), name='inception_5b_3x3_conv'+'2')(inception_5b_3x3)\n","  inception_5b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_3x3_bn'+'2')(inception_5b_3x3)\n","  inception_5b_3x3 = Activation('relu')(inception_5b_3x3)\n","\n","  inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n","\n","  inception_5b_pool = Conv2D(96, (1,1), strides=(1,1), name='inception_5b_pool_conv'+'')(inception_5b_pool)\n","  inception_5b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_pool_bn'+'')(inception_5b_pool)\n","  inception_5b_pool = Activation('relu')(inception_5b_pool)\n","\n","  inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n","\n","  inception_5b_1x1 = Conv2D(256, (1,1), strides=(1,1), name='inception_5b_1x1_conv'+'')(inception_5a)\n","  inception_5b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_1x1_bn'+'')(inception_5b_1x1)\n","  inception_5b_1x1 = Activation('relu')(inception_5b_1x1)\n","\n","  inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n","\n","  av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n","  reshape_layer = Flatten()(av_pool)\n","  dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n","  norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n","\n","  # Final Model\n","  model = Model(inputs=[myInput], outputs=norm_layer)\n","  return model\n","\n","\n","def deepFaceModel():\n","  base_model = Sequential()\n","  base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n","  base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n","  base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n","  base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n","  base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n","  base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n","  base_model.add(Flatten(name='F0'))\n","  base_model.add(Dense(4096, activation='relu', name='F7'))\n","  base_model.add(Dropout(rate=0.5, name='D0'))\n","  base_model.add(Dense(8631, activation='softmax', name='F8'))\n","  return base_model\n","\t\n","\t#---------------------------------\n","def deepIDModel():\n","  myInput = Input(shape=(55, 47, 3))\n","\n","  x = Conv2D(20, (4, 4), name='Conv1', activation='relu', input_shape=(55, 47, 3))(myInput)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool1')(x)\n","  x = Dropout(rate=0.99, name='D1')(x)\n","\n","  x = Conv2D(40, (3, 3), name='Conv2', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool2')(x)\n","  x = Dropout(rate=0.99, name='D2')(x)\n","\n","  x = Conv2D(60, (3, 3), name='Conv3', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool3')(x)\n","  x = Dropout(rate=0.99, name='D3')(x)\n","\n","  x1 = Flatten()(x)\n","  fc11 = Dense(160, name = 'fc11')(x1)\n","\n","  x2 = Conv2D(80, (2, 2), name='Conv4', activation='relu')(x)\n","  x2 = Flatten()(x2)\n","  fc12 = Dense(160, name = 'fc12')(x2)\n","\n","  y = Add()([fc11, fc12])\n","  y = Activation('relu', name = 'deepid')(y)\n","\n","  model = Model(inputs=[myInput], outputs=y)\n","  return model\n","\n","\t\n","def ResNet34():\n","\n","  img_input = tensorflow.keras.layers.Input(shape=(112, 112, 3))\n","\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name='conv1_pad')(img_input)\n","  x = tensorflow.keras.layers.Conv2D(64, 3, strides=1, use_bias=False, kernel_initializer='glorot_normal', name='conv1_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name='conv1_bn')(x)\n","  x = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name='conv1_prelu')(x)\n","  x = stack_fn(x)\n","\n","  model = training.Model(img_input, x, name='ResNet34')\n","\n","  return model\n","\n","\n","\n","def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n","  bn_axis = 3\n","\n","  if conv_shortcut:\n","    shortcut = tensorflow.keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False, kernel_initializer='glorot_normal', name=name + '_0_conv')(x)\n","    shortcut = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_0_bn')(shortcut)\n","  else:\n","    shortcut = x\n","\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_1_bn')(x)\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_1_pad')(x)\n","  x = tensorflow.keras.layers.Conv2D(filters, 3, strides=1, kernel_initializer='glorot_normal', use_bias=False, name=name + '_1_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_2_bn')(x)\n","  x = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name=name + '_1_prelu')(x)\n","\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_2_pad')(x)\n","  x = tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=stride, kernel_initializer='glorot_normal', use_bias=False, name=name + '_2_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_3_bn')(x)\n","\n","  x = tensorflow.keras.layers.Add(name=name + '_add')([shortcut, x])\n","  return x\n","\n","def stack1(x, filters, blocks, stride1=2, name=None):\n","  x = block1(x, filters, stride=stride1, name=name + '_block1')\n","  for i in range(2, blocks + 1):\n","    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n","  return x\n","\n","def stack_fn(x):\n","  x = stack1(x, 64, 3, name='conv2')\n","  x = stack1(x, 128, 4, name='conv3')\n","  x = stack1(x, 256, 6, name='conv4')\n","  return stack1(x, 512, 3, name='conv5')\n","\n","def arcFaceModel():\n","  base_model = ResNet34()\n","  inputs = base_model.inputs[0]\n","  arcface_model = base_model.outputs[0]\n","  arcface_model = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n","  arcface_model = keras.layers.Dropout(0.4)(arcface_model)\n","  arcface_model = keras.layers.Flatten()(arcface_model)\n","  arcface_model = keras.layers.Dense(512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\")(arcface_model)\n","  embedding = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True)(arcface_model)\n","  model = keras.models.Model(inputs, embedding, name=base_model.name)\n","  return model\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AI7vX74oSFha"},"source":["\n","def loadAModel(basemodel,nameOfWheights):\n","  home = \"/content/drive/MyDrive/Models_Herodotou/\"\n","  model = basemodel\n","  output = home+nameOfWheights\n","  model.load_weights(output)\n","  return model\n","\n","\n","def loadFaceNetModel():\n","  return loadAModel(basemodel=InceptionResNetV2(),nameOfWheights='facenet_weights.h5')\n","\n","def loadVGGFaceModel():\n","  model = loadAModel(basemodel=vggbaseModel(),nameOfWheights='vgg_face_weights.h5')\n","  return  Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n","\n","def loadOpenFaceModel():\n","  return loadAModel(basemodel=openFaceModel(),nameOfWheights='openface_weights.h5')\n","\n","def loadDeepFaceModel():\n","  base_model=  loadAModel(basemodel=deepFaceModel(),nameOfWheights='VGGFace2_DeepFace_weights_val-0.9034.h5')\n","  return Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n","\n","def loadDeepIDModel():\n","  return loadAModel(basemodel=deepIDModel(),nameOfWheights='deepid_keras_weights.h5')\n","\n","def loadArcFaceModel():\n","  return loadAModel(basemodel=arcFaceModel(),nameOfWheights='arcface_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmNhwFSuLKf6"},"source":["numberOftrainingPictures= !ls /content/drive/MyDrive/TrustworthyRegression/Training | wc -l\n","numberOfTestPictures= !ls /content/drive/MyDrive/TrustworthyRegression/Test | wc -l\n","\n","\n","numberOftrainingPictures= int(numberOftrainingPictures[0])\n","numberOfTestPictures= int(numberOfTestPictures[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQ3WHp8pLZm8"},"source":["print(numberOftrainingPictures)\n","print(numberOfTestPictures)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4O1CZDdv_Gs"},"source":["base_directory = r\"/content/drive/MyDrive/TrustworthyRegression/\"\n","\n","def readData(numberOfPictures,dirName):\n","  sizeOfInput=(numberOfPictures,160,160,3)\n","  x= np.empty(shape=sizeOfInput,dtype=np.uint8)\n","  y= np.empty(shape=(numberOfPictures,))\n","  aug= list()\n","\n","  directory=base_directory+ dirName+ \"/\"\n","  print(directory)\n","  for index, filename in enumerate(os.listdir(directory)):\n","\n","    img= cv2.imread(directory+filename)\n","    try:\n","      img = img[..., ::-1]\n","      img=img.astype(\"uint8\")\n","    except Exception as e: \n","      print(\"FUUUUCK\\n\"+ filename )\n","      print(e)\n","      continue\n","\n","\n","    rest= filename.split(\"kostis_\")[1]\n","    rest=rest.split(\"_\")\n","    aug_type=rest[0]\n","\n","    label=rest[1] \n","    label= float(label.split(\".jp\")[0])\n","\n","    x[index]=img\n","    y[index]=label\n","    aug.append(aug_type)\n","  \n","  return x,y,aug"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1bDRWp_v_Gt"},"source":["x_train_all, y_train_all, aug_train=readData(numberOfPictures=numberOftrainingPictures\n","                                             ,dirName=\"Training\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xun1m9Nzv_Gt"},"source":["x_test, y_test, aug_test=readData(numberOfPictures=numberOfTestPictures\n","                                             ,dirName=\"Test\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miQsPxXp0bS4"},"source":["plt.imshow(x_test[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh5C82FJy1I3"},"source":["def showUnique(list1):\n","    x = np.array(list1)\n","    print(np.unique(x))\n","\n","from collections import Counter\n","\n","\n","def getImagesDividedByAugType(x, y, aug_method):\n","  showUnique(aug_method)\n","  # print(\"this is a images from the initial read\")\n","  # plt.imshow(x[-1])\n","  # plt.show()\n","  count_of_items= Counter(aug_method)\n","  print(count_of_items)\n","  ImagesDividedByAugType={}\n","  for key, value in count_of_items.items():\n","    numberOfPictures=value\n","    sizeOfInput=(numberOfPictures,160,160,3)\n","    # print(sizeOfInput)\n","\n","    current_x= np.empty(shape=sizeOfInput,dtype=np.uint8)\n","    current_y= np.empty(shape=(numberOfPictures,))\n","    current_aug_type=list()\n","    counter=0;\n","    ImagesDividedByAugType[key]={\"x\":current_x,\"y\":current_y,\"aug_type\": current_aug_type,\"counter\":counter}\n","  \n","  for index, picture in enumerate(x):\n","    dic= ImagesDividedByAugType[aug_method[index]]\n","    dic[\"x\"][dic[\"counter\"]]=picture\n","    # plt.imshow(picture)\n","    # plt.show()\n","    # plt.imshow(dic[\"x\"][dic[\"counter\"]])\n","    # plt.show()\n","    # break;\n","    dic[\"y\"][dic[\"counter\"]]=y[index]\n","    dic[\"aug_type\"].append(aug_method[index])\n","    dic[\"counter\"]=dic[\"counter\"]+1\n","\n","    ImagesDividedByAugType[aug_method[index]]=dic\n","  return ImagesDividedByAugType\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"byP2Hdue5cbh"},"source":["facenet= loadFaceNetModel()\n","vggface= loadVGGFaceModel()\n","openface=loadOpenFaceModel()\n","deepface=loadDeepFaceModel()\n","deepID=loadDeepIDModel()\n","arcFace=loadArcFaceModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1D18neYPo6Ty"},"source":["# face_recognition_models=[facenet,vggface,openface, deepface,deepID,arcFace]\n","face_recognition_models=[facenet,vggface,openface, deepface,deepID, arcFace ]\n","face_recognition_models_names=[\"facenet\",\"vggface\",\"openface\", \"deepface\",\"deepID\", \"arcFace\"]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOFo1zJY-oRw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFpgXrs21mvF"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dq1mq-T7rWk0"},"source":["%cd /content/drive/MyDrive/TrustworthyRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwFNHdXxhUDh"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ULyPly3AhYA0"},"source":["!mkdir FaceEncodings\n","\n","!mkdir FaceEncodings/Training\n","!mkdir FaceEncodings/Training/HF\n","!mkdir FaceEncodings/Training/None\n","!mkdir FaceEncodings/Training/RO\n","!mkdir FaceEncodings/Training/RO-RC\n","!mkdir FaceEncodings/Training/HF-RC\n","!mkdir FaceEncodings/Training/RO-TR\n","!mkdir FaceEncodings/Training/None-RC\n","!mkdir FaceEncodings/Training/None-TR\n","!mkdir FaceEncodings/Training/HF-TR\n","\n","!mkdir FaceEncodings/Test\n","!mkdir FaceEncodings/Test/HF\n","!mkdir FaceEncodings/Test/None\n","!mkdir FaceEncodings/Test/RO\n","!mkdir FaceEncodings/Test/RO-RC\n","!mkdir FaceEncodings/Test/HF-RC\n","!mkdir FaceEncodings/Test/RO-TR\n","!mkdir FaceEncodings/Test/None-RC\n","!mkdir FaceEncodings/Test/None-TR\n","!mkdir FaceEncodings/Test/HF-TR\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ELgpChz_Gqi"},"source":["%cd FaceEncodings  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1yT17Pa_F-G"},"source":["\n","\n","imagesDividedByAugType_test=getImagesDividedByAugType(x=x_test, y=y_test, aug_method=aug_test)\n","imagesDividedByAugType_training=getImagesDividedByAugType(x=x_train_all, y=y_train_all, aug_method=aug_train)\n","\n","\n","\n","plt.imshow(imagesDividedByAugType_training[\"None\"][\"x\"][1])\n","plt.show()\n","print(imagesDividedByAugType_training[\"None\"][\"aug_type\"][-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPklNbt7s2S3"},"source":["print(imagesDividedByAugType.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvoMZkUtfzRF"},"source":["def embedings_toString(embednings, desiredOutputs):\n","  toPutInFile=\"\"\n","  toPutInFile= toPutInFile+ str(len(embednings))+ \",\"+str(embednings[0].shape[0])+ \"\\n\"\n","  for index, emb in enumerate(embednings):\n","    s=\"[\"\n","    for number in emb:\n","      s=s+str(number)+\",\"\n","    s=s+\"]\"+str(desiredOutputs[index])+ \"\\n\"\n","    # toPutInFile=toPutInFile+ s\n","    toPutInFile=toPutInFile + s\n","  return toPutInFile\n","\n","def saveEmbedingsForModel(embednings,desiredOutputs, augment_type, model_name , dir_type=\"\"):\n","  toPutInFile=embedings_toString(embednings,desiredOutputs)\n","  base=\"/content/drive/MyDrive/TrustworthyRegression/FaceEncodings/\"+ dir_type\n","  filename=base+augment_type+\"/\" +model_name+\".txt\"\n","  f = open(filename, \"w\")\n","  f.write(toPutInFile)\n","  f.close()  \n","  print(filename+ \" DONE!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MJsnF1Kse1k"},"source":["def saveEmb(imagesDividedByAugType, face_recognition_models,face_recognition_models_names, dir_type=\"\"):\n","  for key, dic in imagesDividedByAugType.items():\n","    # dic=={\"x\":x,\"y\":y,\"aug_type\": aug_type,\"counter\":counter}\n","    FRimages= getFaceImages(images=dic[\"x\"], listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True)\n","    for index, model in enumerate(face_recognition_models):\n","      model_list=[model]\n","      model_name=face_recognition_models_names[index]\n","\n","      tempImage=FRimages[0]\n","      sizeOfFinalinput=getSizeOfEmbedings(tempImage,model_list)\n","      # print(\"sizeOfFinalinput \"+str(sizeOfFinalinput) )\n","      embedings=getEmbedings(FRimages,model_list, sizeOfFinalInput=sizeOfFinalinput)\n","      saveEmbedingsForModel(embednings=embedings,desiredOutputs=dic[\"y\"] , augment_type=key, model_name= model_name,dir_type=dir_type)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1KbsWizCm_G"},"source":["saveEmb(imagesDividedByAugType_test, face_recognition_models,face_recognition_models_names, dir_type=\"Test/\")\n","\n","# imagesDividedByAugType_test=getImagesDividedByAugType(x=x_test, y=y_test, aug_method=aug_test)\n","# imagesDividedByAugType_training=getImagesDividedByAugType(x=x_train_all, y=y_train_all, aug_method=aug_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PDncdexFXfR"},"source":["saveEmb(imagesDividedByAugType_training, face_recognition_models,face_recognition_models_names, dir_type=\"Training/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ej-bi5mHa280"},"source":["# def readEmbedings(listOfDesiredAugmentation, listOfDesiredModelNames):\n","#   listOfAugEmbedings=list()\n","#   for directory in listOfDesiredAugmentation:\n","#     listOfAllModelEmbedings=list()\n","#     for modelName in listOfDesiredModelNames:\n","#       filename= directory+\"/\"+ modelName+\".txt\"\n","#       with open( filename, \"r\") as a_file:\n","#         firstline= a_file[0].split(\",\")\n","#         numberOfEmbedings=int(firstline[0])\n","#         embedingsSize    =int(firstline[1])\n","\n","#         currentEmbedings= np.empty((numberOfEmbedings,embedingsSize) )\n","#         for outterIndex, line in enumerate(a_file[1:]):\n","#           stripped_line = line.strip()\n","#           line = stripped_line.split(\"[\")[1]\n","#           line=line.split(\"]\")[0]\n","#           numbers=line.split(\",\")\n","#           numbers = numbers[:-1]\n","#           for index, number in enumerate(numbers):\n","#               numbers[index]=float(number)\n","#           currentEmbedings[outterIndex]=numbers\n","#         listOfAllModelEmbedings.append(currentEmbedings)\n","\n","#     # numberOfJoinedEmbedings=0    \n","#     # for embeding in  listOfAllModelEmbedings:\n","#     #    numberOfJoinedEmbedings=numberOfJoinedEmbedings+embeding.shape[1]\n","    \n","#     # modelEmbedings= np.empty((len(listOfAllModelEmbedings[0]),numberOfJoinedEmbedings))\n","#     # modelEmbedingIndex=0;\n","#     # for embeding in listOfAllModelEmbedings:\n","#     setOfEmedings=set()\n","#     for modelEmbedings in  listOfAllModelEmbedings:\n","#       setOfEmedings.add(modelEmbedings)\n","#     AugEmbedings= np.concatenate(setOfEmedings, axis=1)\n","#     listOfAugEmbedings.append(AugEmbedings)\n","\n","#   setOfEmedings=set()\n","#   for augEmbedings in  listOfAugEmbedings:\n","#     setOfEmedings.add(augEmbedings)\n","#   AugEmbedings= np.concatenate(setOfEmedings, axis=0)\n","#   return AugEmbedings\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwSDlPrmXXZe"},"source":["def readEmbedings(listOfDesiredAugmentation, listOfDesiredModelNames):\n","  listOfAugEmbedings=list()\n","  listOfAugLabels=list()\n","  \n","  for directory in listOfDesiredAugmentation:\n","    listOfAllModelEmbedings=list()\n","\n","    for isFirst, modelName in enumerate(listOfDesiredModelNames):\n","      filename= directory+\"/\"+ modelName+\".txt\"\n","      firstLineInDoc=True\n","      with open( filename, \"r\") as a_file:\n","        currentEmbedings= None\n","        currentlabels= None\n","        for outterIndex, line in enumerate(a_file):\n","          if (firstLineInDoc==True):\n","            firstline= line.split(\",\")\n","            numberOfEmbedings=int(firstline[0])\n","            embedingsSize    =int(firstline[1])\n","            currentEmbedings= np.empty((numberOfEmbedings,embedingsSize) )\n","            currentlabels= np.empty((numberOfEmbedings) )\n","            firstLineInDoc=False\n","            continue\n","\n","          stripped_line = line.strip()\n","          line = stripped_line.split(\"[\")[1]\n","          parts=line.split(\"]\")\n","          numbers=parts[0]\n","          numbers=numbers.split(\",\")\n","          numbers = numbers[:-1]\n","          for index, number in enumerate(numbers):\n","              numbers[index]=float(number)\n","          currentEmbedings[outterIndex-1]=numbers\n","          if(isFirst==0):\n","            label=float(parts[1])\n","            currentlabels[outterIndex-1]=label\n","        if(isFirst==0):\n","          listOfAugLabels.append(currentlabels)\n","        listOfAllModelEmbedings.append(currentEmbedings)\n","\n","    AugEmbedings= np.concatenate(listOfAllModelEmbedings, axis=1)\n","    listOfAugEmbedings.append(AugEmbedings)\n","\n","  AugEmbedings= np.concatenate(listOfAugEmbedings, axis=0)\n","  AugLabels= np.concatenate(listOfAugLabels, axis=0)\n","\n","  return AugEmbedings,AugLabels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0CVx47Y0Ket"},"source":["# Write in the csv the **embedings**"]},{"cell_type":"code","metadata":{"id":"CCGYohjk0FMf"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yX5w09mo0FMk"},"source":["#IMPORTS\n","# from keras.utils.np_utils import to_categorical\n","# # import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# # import brewer2mpl\n","# import sys\n","# import warnings\n","import os\n","# import tensorflow as tf\n","# import keras_preprocessing\n","# from keras_preprocessing import image\n","# from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","# import PIL\n","# import PIL.Image\n","# import pathlib\n","# import matplotlib.pyplot as plt\n","# from tensorflow.keras import regularizers\n","# Heinitializer = tf.keras.initializers.HeNormal()\n","# import glob\n","# import imageio\n","# import matplotlib.pyplot as plt\n","# import numpy as np\n","# import os\n","# import PIL\n","# from tensorflow.keras import layers\n","# import time\n","\n","# from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvzM-k_pRmEB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLV_61Av0FMl"},"source":["initial_df = pd.read_csv (r'/content/drive/MyDrive/CFD 3.0 Norming Data and Codebook.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhPvU5CQ0FMl"},"source":["listOfUsefulColumns=['Model',\n"," 'EthnicitySelf',\n"," 'GenderSelf',\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n","#  'Suitability',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian']\n","df=initial_df[listOfUsefulColumns]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aOlflEx0FMm"},"source":["# delete a single row by index value 0\n","df = df.drop(labels=0, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjtKhmw30FMn"},"source":["df[\"image\"] = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2D-PTpKI0FMo"},"source":["directory = r'/content/drive/MyDrive/CFD/N/'\n","for filename in os.listdir(directory):\n","  parts=filename.split(\".\")\n","  if parts[0] in list(df[\"Model\"]):\n","      img= cv2.imread(directory+filename)\n","      img = img[..., ::-1]\n","      img=img.astype(np.uint8)\n","      listWrappedImage=[img]\n","      df[\"image\"][df.index[df[\"Model\"]==parts[0]]]=listWrappedImage\n","  else:\n","      continue\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rz07hmuY0FMo"},"source":["checkPointDF=df.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_kdCTj70FMo"},"source":["# **Here is the CHECKPOINT**"]},{"cell_type":"code","metadata":{"id":"y3j5k1O02cCB"},"source":["!pip install deepface"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XV3G5Obh2cCB"},"source":["from pathlib import Path\n","import gdown\n","from functools import partial\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras import backend as K\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Input, concatenate\n","from tensorflow.keras.layers import Dense, Activation, Lambda, Flatten, BatchNormalization\n","from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.models import load_model\n","tf_version = int(tf.__version__.split(\".\")[0])\n","from tensorflow.python.keras import backend\n","from tensorflow.python.keras.engine import training\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.python.keras.utils import layer_utils\n","from tensorflow.python.lib.io import file_io\n","import tensorflow\n","import zipfile\n","from tensorflow.keras.layers import Convolution2D, LocallyConnected2D, Add, Dropout\n","from tensorflow.keras.layers import Concatenate\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaiFGyD72cCC"},"source":["def scaling(x, scale):\n","\treturn x * scale\n","\n","def InceptionResNetV2():\n","\t\n","\tinputs = Input(shape=(160, 160, 3))\n","\tx = Conv2D(32, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_1a_3x3') (inputs)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_1a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_1a_3x3_Activation')(x)\n","\tx = Conv2D(32, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_2a_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_2a_3x3_Activation')(x)\n","\tx = Conv2D(64, 3, strides=1, padding='same', use_bias=False, name= 'Conv2d_2b_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_2b_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_2b_3x3_Activation')(x)\n","\tx = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n","\tx = Conv2D(80, 1, strides=1, padding='valid', use_bias=False, name= 'Conv2d_3b_1x1') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_3b_1x1_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_3b_1x1_Activation')(x)\n","\tx = Conv2D(192, 3, strides=1, padding='valid', use_bias=False, name= 'Conv2d_4a_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4a_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_4a_3x3_Activation')(x)\n","\tx = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Conv2d_4b_3x3') (x)\n","\tx = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Conv2d_4b_3x3_BatchNorm')(x)\n","\tx = Activation('relu', name='Conv2d_4b_3x3_Activation')(x)\n","\t\n","\t# 5x Block35 (Inception-ResNet-A block):\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_1_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_1_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_1_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_1_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_2_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_2_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_2_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_2_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_3_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_3_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_3_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_3_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_4_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_4_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_4_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_4_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block35_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block35_5_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(32, 1, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(32, 3, strides=1, padding='same', use_bias=False, name= 'Block35_5_Branch_2_Conv2d_0c_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Block35_5_Branch_2_Conv2d_0c_3x3_Activation')(branch_2)\n","\tbranches = [branch_0, branch_1, branch_2]\n","\tmixed = Concatenate(axis=3, name='Block35_5_Concatenate')(branches)\n","\tup = Conv2D(256, 1, strides=1, padding='same', use_bias=True, name= 'Block35_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block35_5_Activation')(x)\n","\n","\t# Mixed 6a (Reduction-A block):\n","\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_0_Conv2d_1a_3x3') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_0b_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_6a_Branch_1_Conv2d_1a_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n","\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_6a_Branch_2_MaxPool_1a_3x3')(x)\n","\tbranches = [branch_0, branch_1, branch_pool]\n","\tx = Concatenate(axis=3, name='Mixed_6a')(branches)\n","\n","\t# 10x Block17 (Inception-ResNet-B block):\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_1_Branch_1_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_1_Branch_1_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_1_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_2_Branch_2_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_2_Branch_2_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_2_Branch_2_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_2_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_3_Branch_3_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_3_Branch_3_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_3_Branch_3_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_3_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_4_Branch_4_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_4_Branch_4_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_4_Branch_4_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_4_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_5_Branch_5_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_5_Branch_5_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_5_Branch_5_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_5_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_5_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_6_Branch_6_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_6_Branch_6_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_6_Branch_6_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_6_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_6_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_6_Activation')(x)\t\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_7_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_7_Branch_7_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_7_Branch_7_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_7_Branch_7_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_7_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_7_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_7_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_8_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_8_Branch_8_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_8_Branch_8_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_8_Branch_8_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_8_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_8_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_8_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_9_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_9_Branch_9_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_9_Branch_9_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_9_Branch_9_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_9_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_9_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_9_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block17_10_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(128, 1, strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [1, 7], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0b_1x7') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0b_1x7_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0b_1x7_Activation')(branch_1)\n","\tbranch_1 = Conv2D(128, [7, 1], strides=1, padding='same', use_bias=False, name= 'Block17_10_Branch_10_Conv2d_0c_7x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block17_10_Branch_10_Conv2d_0c_7x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block17_10_Branch_10_Conv2d_0c_7x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block17_10_Concatenate')(branches)\n","\tup = Conv2D(896, 1, strides=1, padding='same', use_bias=True, name= 'Block17_10_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block17_10_Activation')(x)\n","\n","\t# Mixed 7a (Reduction-B block): 8 x 8 x 2080\t\n","\tbranch_0 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_0a_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation')(branch_0)\n","\tbranch_0 = Conv2D(384, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_0_Conv2d_1a_3x3') (branch_0)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation')(branch_0)\n","\tbranch_1 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_1_Conv2d_1a_3x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation')(branch_1)\n","\tbranch_2 = Conv2D(256, 1, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation')(branch_2)\n","\tbranch_2 = Conv2D(256, 3, strides=1, padding='same', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_0b_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation')(branch_2)\n","\tbranch_2 = Conv2D(256, 3, strides=2, padding='valid', use_bias=False, name= 'Mixed_7a_Branch_2_Conv2d_1a_3x3') (branch_2)\n","\tbranch_2 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm')(branch_2)\n","\tbranch_2 = Activation('relu', name='Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation')(branch_2)\n","\tbranch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_7a_Branch_3_MaxPool_1a_3x3')(x)\n","\tbranches = [branch_0, branch_1, branch_2, branch_pool]\n","\tx = Concatenate(axis=3, name='Mixed_7a')(branches)\n","\n","\t# 5x Block8 (Inception-ResNet-C block):\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_1_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_1_Branch_1_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_1_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_1_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_1_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_1_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_2_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_2_Branch_2_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_2_Branch_2_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_2_Branch_2_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_2_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_2_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_2_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_3_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_3_Branch_3_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_3_Branch_3_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_3_Branch_3_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_3_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_3_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_3_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_4_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_4_Branch_4_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_4_Branch_4_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_4_Branch_4_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_4_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_4_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_4_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_5_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_5_Branch_5_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_5_Branch_5_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_5_Branch_5_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_5_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_5_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","\tx = add([x, up])\n","\tx = Activation('relu', name='Block8_5_Activation')(x)\n","\t\n","\tbranch_0 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_0_Conv2d_1x1') (x)\n","\tbranch_0 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_0_Conv2d_1x1_BatchNorm')(branch_0)\n","\tbranch_0 = Activation('relu', name='Block8_6_Branch_0_Conv2d_1x1_Activation')(branch_0)\n","\tbranch_1 = Conv2D(192, 1, strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0a_1x1') (x)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0a_1x1_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [1, 3], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0b_1x3') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0b_1x3_Activation')(branch_1)\n","\tbranch_1 = Conv2D(192, [3, 1], strides=1, padding='same', use_bias=False, name= 'Block8_6_Branch_1_Conv2d_0c_3x1') (branch_1)\n","\tbranch_1 = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name='Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm')(branch_1)\n","\tbranch_1 = Activation('relu', name='Block8_6_Branch_1_Conv2d_0c_3x1_Activation')(branch_1)\n","\tbranches = [branch_0, branch_1]\n","\tmixed = Concatenate(axis=3, name='Block8_6_Concatenate')(branches)\n","\tup = Conv2D(1792, 1, strides=1, padding='same', use_bias=True, name= 'Block8_6_Conv2d_1x1') (mixed)\n","\tup = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 1})(up)\n","\tx = add([x, up])\n","\t\n","\t# Classification block\n","\tx = GlobalAveragePooling2D(name='AvgPool')(x)\n","\tx = Dropout(1.0 - 0.8, name='Dropout')(x)\n","\t# Bottleneck\n","\tx = Dense(128, use_bias=False, name='Bottleneck')(x)\n","\tx = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name='Bottleneck_BatchNorm')(x)\n","\n","\t# Create model\n","\tmodel = Model(inputs, x, name='inception_resnet_v1')\n","\n","\treturn model\n","\n","\n","\n","\n","#---------------------------------------\n","\n","def vggbaseModel():\n","\tmodel = Sequential()\n","\tmodel.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n","\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(64, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(128, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(256, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(ZeroPadding2D((1,1)))\n","\tmodel.add(Convolution2D(512, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","\tmodel.add(Convolution2D(4096, (7, 7), activation='relu'))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Convolution2D(4096, (1, 1), activation='relu'))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Convolution2D(2622, (1, 1)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Activation('softmax'))\n","\t\n","\treturn model\n","\n","\n","\n","#---------------------------------------\n","\n","def openFaceModel():\n","  myInput = Input(shape=(96, 96, 3))\n","\n","  x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n","  x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n","  x = Activation('relu')(x)\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = MaxPooling2D(pool_size=3, strides=2)(x)\n","  x = Lambda(lambda x: tf.nn.lrn(x, alpha=1e-4, beta=0.75), name='lrn_1')(x)\n","  x = Conv2D(64, (1, 1), name='conv2')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n","  x = Activation('relu')(x)\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = Conv2D(192, (3, 3), name='conv3')(x)\n","  x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n","  x = Activation('relu')(x)\n","  x = Lambda(lambda x: tf.nn.lrn(x, alpha=1e-4, beta=0.75), name='lrn_2')(x) #x is equal added\n","  x = ZeroPadding2D(padding=(1, 1))(x)\n","  x = MaxPooling2D(pool_size=3, strides=2)(x)\n","\n","  # Inception3a\n","  inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n","  inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n","  inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n","  inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n","  inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n","  inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n","  inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n","\n","  inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n","  inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n","  inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n","  inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n","  inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n","  inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n","  inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n","\n","  inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n","  inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n","  inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n","  inception_3a_pool = Activation('relu')(inception_3a_pool)\n","  inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n","\n","  inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n","  inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n","  inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n","\n","  inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n","\n","  # Inception3b\n","  inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n","  inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n","  inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n","  inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n","  inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n","  inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n","  inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n","\n","  inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n","  inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n","  inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n","  inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n","  inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n","  inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n","  inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n","\n","  inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n","  inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n","  inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n","  inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n","  inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n","  inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n","  inception_3b_pool = Activation('relu')(inception_3b_pool)\n","  inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n","\n","  inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n","  inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n","  inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n","\n","  inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n","\n","  # Inception3c\n","  inception_3c_3x3 = Conv2D(128, (1, 1), strides=(1, 1), name='inception_3c_3x3_conv1')(inception_3b)\n","  inception_3c_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_3x3_bn1')(inception_3c_3x3)\n","  inception_3c_3x3 = Activation('relu')(inception_3c_3x3)\n","  inception_3c_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3c_3x3)\n","  inception_3c_3x3 = Conv2D(256, (3, 3), strides=(2, 2), name='inception_3c_3x3_conv'+'2')(inception_3c_3x3)\n","  inception_3c_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_3x3_bn'+'2')(inception_3c_3x3)\n","  inception_3c_3x3 = Activation('relu')(inception_3c_3x3)\n","\n","  inception_3c_5x5 = Conv2D(32, (1, 1), strides=(1, 1), name='inception_3c_5x5_conv1')(inception_3b)\n","  inception_3c_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_5x5_bn1')(inception_3c_5x5)\n","  inception_3c_5x5 = Activation('relu')(inception_3c_5x5)\n","  inception_3c_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3c_5x5)\n","  inception_3c_5x5 = Conv2D(64, (5, 5), strides=(2, 2), name='inception_3c_5x5_conv'+'2')(inception_3c_5x5)\n","  inception_3c_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3c_5x5_bn'+'2')(inception_3c_5x5)\n","  inception_3c_5x5 = Activation('relu')(inception_3c_5x5)\n","\n","  inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n","  inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n","\n","  inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n","\n","  #inception 4a\n","  inception_4a_3x3 = Conv2D(96, (1, 1), strides=(1, 1), name='inception_4a_3x3_conv'+'1')(inception_3c)\n","  inception_4a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_3x3_bn'+'1')(inception_4a_3x3)\n","  inception_4a_3x3 = Activation('relu')(inception_4a_3x3)\n","  inception_4a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3)\n","  inception_4a_3x3 = Conv2D(192, (3, 3), strides=(1, 1), name='inception_4a_3x3_conv'+'2')(inception_4a_3x3)\n","  inception_4a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_3x3_bn'+'2')(inception_4a_3x3)\n","  inception_4a_3x3 = Activation('relu')(inception_4a_3x3)\n","\n","  inception_4a_5x5 = Conv2D(32, (1,1), strides=(1,1), name='inception_4a_5x5_conv1')(inception_3c)\n","  inception_4a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_5x5_bn1')(inception_4a_5x5)\n","  inception_4a_5x5 = Activation('relu')(inception_4a_5x5)\n","  inception_4a_5x5 = ZeroPadding2D(padding=(2,2))(inception_4a_5x5)\n","  inception_4a_5x5 = Conv2D(64, (5,5), strides=(1,1), name='inception_4a_5x5_conv'+'2')(inception_4a_5x5)\n","  inception_4a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_5x5_bn'+'2')(inception_4a_5x5)\n","  inception_4a_5x5 = Activation('relu')(inception_4a_5x5)\n","\n","  inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n","  inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n","  inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n","  inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n","\n","  inception_4a_pool = Conv2D(128, (1,1), strides=(1,1), name='inception_4a_pool_conv'+'')(inception_4a_pool)\n","  inception_4a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_pool_bn'+'')(inception_4a_pool)\n","  inception_4a_pool = Activation('relu')(inception_4a_pool)\n","  inception_4a_pool = ZeroPadding2D(padding=(2, 2))(inception_4a_pool)\n","\n","  inception_4a_1x1 = Conv2D(256, (1, 1), strides=(1, 1), name='inception_4a_1x1_conv'+'')(inception_3c)\n","  inception_4a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4a_1x1_bn'+'')(inception_4a_1x1)\n","  inception_4a_1x1 = Activation('relu')(inception_4a_1x1)\n","\n","  inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n","\n","  #inception4e\n","  inception_4e_3x3 = Conv2D(160, (1,1), strides=(1,1), name='inception_4e_3x3_conv'+'1')(inception_4a)\n","  inception_4e_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_3x3_bn'+'1')(inception_4e_3x3)\n","  inception_4e_3x3 = Activation('relu')(inception_4e_3x3)\n","  inception_4e_3x3 = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3)\n","  inception_4e_3x3 = Conv2D(256, (3,3), strides=(2,2), name='inception_4e_3x3_conv'+'2')(inception_4e_3x3)\n","  inception_4e_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_3x3_bn'+'2')(inception_4e_3x3)\n","  inception_4e_3x3 = Activation('relu')(inception_4e_3x3)\n","\n","  inception_4e_5x5 = Conv2D(64, (1,1), strides=(1,1), name='inception_4e_5x5_conv'+'1')(inception_4a)\n","  inception_4e_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_5x5_bn'+'1')(inception_4e_5x5)\n","  inception_4e_5x5 = Activation('relu')(inception_4e_5x5)\n","  inception_4e_5x5 = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5)\n","  inception_4e_5x5 = Conv2D(128, (5,5), strides=(2,2), name='inception_4e_5x5_conv'+'2')(inception_4e_5x5)\n","  inception_4e_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_4e_5x5_bn'+'2')(inception_4e_5x5)\n","  inception_4e_5x5 = Activation('relu')(inception_4e_5x5)\n","\n","  inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n","  inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n","\n","  inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n","\n","  #inception5a\n","  inception_5a_3x3 = Conv2D(96, (1,1), strides=(1,1), name='inception_5a_3x3_conv'+'1')(inception_4e)\n","  inception_5a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_3x3_bn'+'1')(inception_5a_3x3)\n","  inception_5a_3x3 = Activation('relu')(inception_5a_3x3)\n","  inception_5a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3)\n","  inception_5a_3x3 = Conv2D(384, (3,3), strides=(1,1), name='inception_5a_3x3_conv'+'2')(inception_5a_3x3)\n","  inception_5a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_3x3_bn'+'2')(inception_5a_3x3)\n","  inception_5a_3x3 = Activation('relu')(inception_5a_3x3)\n","\n","  inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n","  inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n","  inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n","  inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n","\n","  inception_5a_pool = Conv2D(96, (1,1), strides=(1,1), name='inception_5a_pool_conv'+'')(inception_5a_pool)\n","  inception_5a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_pool_bn'+'')(inception_5a_pool)\n","  inception_5a_pool = Activation('relu')(inception_5a_pool)\n","  inception_5a_pool = ZeroPadding2D(padding=(1,1))(inception_5a_pool)\n","\n","  inception_5a_1x1 = Conv2D(256, (1,1), strides=(1,1), name='inception_5a_1x1_conv'+'')(inception_4e)\n","  inception_5a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5a_1x1_bn'+'')(inception_5a_1x1)\n","  inception_5a_1x1 = Activation('relu')(inception_5a_1x1)\n","\n","  inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n","\n","  #inception_5b\n","  inception_5b_3x3 = Conv2D(96, (1,1), strides=(1,1), name='inception_5b_3x3_conv'+'1')(inception_5a)\n","  inception_5b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_3x3_bn'+'1')(inception_5b_3x3)\n","  inception_5b_3x3 = Activation('relu')(inception_5b_3x3)\n","  inception_5b_3x3 = ZeroPadding2D(padding=(1,1))(inception_5b_3x3)\n","  inception_5b_3x3 = Conv2D(384, (3,3), strides=(1,1), name='inception_5b_3x3_conv'+'2')(inception_5b_3x3)\n","  inception_5b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_3x3_bn'+'2')(inception_5b_3x3)\n","  inception_5b_3x3 = Activation('relu')(inception_5b_3x3)\n","\n","  inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n","\n","  inception_5b_pool = Conv2D(96, (1,1), strides=(1,1), name='inception_5b_pool_conv'+'')(inception_5b_pool)\n","  inception_5b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_pool_bn'+'')(inception_5b_pool)\n","  inception_5b_pool = Activation('relu')(inception_5b_pool)\n","\n","  inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n","\n","  inception_5b_1x1 = Conv2D(256, (1,1), strides=(1,1), name='inception_5b_1x1_conv'+'')(inception_5a)\n","  inception_5b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_5b_1x1_bn'+'')(inception_5b_1x1)\n","  inception_5b_1x1 = Activation('relu')(inception_5b_1x1)\n","\n","  inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n","\n","  av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n","  reshape_layer = Flatten()(av_pool)\n","  dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n","  norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n","\n","  # Final Model\n","  model = Model(inputs=[myInput], outputs=norm_layer)\n","  return model\n","\n","\n","def deepFaceModel():\n","  base_model = Sequential()\n","  base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n","  base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n","  base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n","  base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n","  base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n","  base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n","  base_model.add(Flatten(name='F0'))\n","  base_model.add(Dense(4096, activation='relu', name='F7'))\n","  base_model.add(Dropout(rate=0.5, name='D0'))\n","  base_model.add(Dense(8631, activation='softmax', name='F8'))\n","  return base_model\n","\t\n","\t#---------------------------------\n","def deepIDModel():\n","  myInput = Input(shape=(55, 47, 3))\n","\n","  x = Conv2D(20, (4, 4), name='Conv1', activation='relu', input_shape=(55, 47, 3))(myInput)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool1')(x)\n","  x = Dropout(rate=0.99, name='D1')(x)\n","\n","  x = Conv2D(40, (3, 3), name='Conv2', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool2')(x)\n","  x = Dropout(rate=0.99, name='D2')(x)\n","\n","  x = Conv2D(60, (3, 3), name='Conv3', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool3')(x)\n","  x = Dropout(rate=0.99, name='D3')(x)\n","\n","  x1 = Flatten()(x)\n","  fc11 = Dense(160, name = 'fc11')(x1)\n","\n","  x2 = Conv2D(80, (2, 2), name='Conv4', activation='relu')(x)\n","  x2 = Flatten()(x2)\n","  fc12 = Dense(160, name = 'fc12')(x2)\n","\n","  y = Add()([fc11, fc12])\n","  y = Activation('relu', name = 'deepid')(y)\n","\n","  model = Model(inputs=[myInput], outputs=y)\n","  return model\n","\n","\t\n","def ResNet34():\n","\n","  img_input = tensorflow.keras.layers.Input(shape=(112, 112, 3))\n","\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name='conv1_pad')(img_input)\n","  x = tensorflow.keras.layers.Conv2D(64, 3, strides=1, use_bias=False, kernel_initializer='glorot_normal', name='conv1_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name='conv1_bn')(x)\n","  x = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name='conv1_prelu')(x)\n","  x = stack_fn(x)\n","\n","  model = training.Model(img_input, x, name='ResNet34')\n","\n","  return model\n","\n","\n","\n","def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n","  bn_axis = 3\n","\n","  if conv_shortcut:\n","    shortcut = tensorflow.keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False, kernel_initializer='glorot_normal', name=name + '_0_conv')(x)\n","    shortcut = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_0_bn')(shortcut)\n","  else:\n","    shortcut = x\n","\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_1_bn')(x)\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_1_pad')(x)\n","  x = tensorflow.keras.layers.Conv2D(filters, 3, strides=1, kernel_initializer='glorot_normal', use_bias=False, name=name + '_1_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_2_bn')(x)\n","  x = tensorflow.keras.layers.PReLU(shared_axes=[1, 2], name=name + '_1_prelu')(x)\n","\n","  x = tensorflow.keras.layers.ZeroPadding2D(padding=1, name=name + '_2_pad')(x)\n","  x = tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=stride, kernel_initializer='glorot_normal', use_bias=False, name=name + '_2_conv')(x)\n","  x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_3_bn')(x)\n","\n","  x = tensorflow.keras.layers.Add(name=name + '_add')([shortcut, x])\n","  return x\n","\n","def stack1(x, filters, blocks, stride1=2, name=None):\n","  x = block1(x, filters, stride=stride1, name=name + '_block1')\n","  for i in range(2, blocks + 1):\n","    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n","  return x\n","\n","def stack_fn(x):\n","  x = stack1(x, 64, 3, name='conv2')\n","  x = stack1(x, 128, 4, name='conv3')\n","  x = stack1(x, 256, 6, name='conv4')\n","  return stack1(x, 512, 3, name='conv5')\n","\n","def arcFaceModel():\n","  base_model = ResNet34()\n","  inputs = base_model.inputs[0]\n","  arcface_model = base_model.outputs[0]\n","  arcface_model = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n","  arcface_model = keras.layers.Dropout(0.4)(arcface_model)\n","  arcface_model = keras.layers.Flatten()(arcface_model)\n","  arcface_model = keras.layers.Dense(512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\")(arcface_model)\n","  embedding = keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True)(arcface_model)\n","  model = keras.models.Model(inputs, embedding, name=base_model.name)\n","  return model\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P27vYggO2cCF"},"source":["\n","# def loadAModel(basemodel,nameOfWheights):\n","#   home = \"/content/drive/MyDrive/Models_Herodotou/\"\n","#   model = basemodel\n","#   output = home+nameOfWheights\n","#   model.load_weights(output)\n","#   return model\n","\n","\n","# def loadFaceNetModel():\n","#   return loadAModel(basemodel=InceptionResNetV2(),nameOfWheights='facenet_weights.h5')\n","\n","# def loadVGGFaceModel():\n","#   model = loadAModel(basemodel=vggbaseModel(),nameOfWheights='vgg_face_weights.h5')\n","#   return  Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n","\n","# def loadOpenFaceModel():\n","#   return loadAModel(basemodel=openFaceModel(),nameOfWheights='openface_weights.h5')\n","\n","# def loadDeepFaceModel():\n","#   base_model=  loadAModel(basemodel=deepFaceModel(),nameOfWheights='VGGFace2_DeepFace_weights_val-0.9034.h5')\n","#   return Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n","\n","# def loadDeepIDModel():\n","#   return loadAModel(basemodel=deepIDModel(),nameOfWheights='deepid_keras_weights.h5')\n","\n","# def loadArcFaceModel():\n","#   return loadAModel(basemodel=arcFaceModel(),nameOfWheights='arcface_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1LkCbSlPqlL"},"source":["def putResizeLayerInModel(model, actualInputShape=(160, 160, 3)):\n","  input_size=functions.find_input_shape(model)\n","\n","  toBeModel=tf.keras.Sequential()\n","  toBeModel.add(Input(shape=actualInputShape))\n","  toBeModel.add(tf.keras.layers.experimental.preprocessing.Resizing(height=input_size[0],\n","                                                                width=input_size[1]))\n","  toBeModel.add(model)\n","  return toBeModel\n","\n","def loadAModel(basemodel,nameOfWheights):\n","  home = \"/content/drive/MyDrive/Models_Herodotou/\"\n","  model = basemodel\n","  output = home+nameOfWheights\n","  model.load_weights(output)\n","  return model\n","\n","\n","def loadFaceNetModel(useResizeLayerInModel=False):\n","  model=loadAModel(basemodel=InceptionResNetV2(),nameOfWheights='facenet_weights.h5')\n","  if(useResizeLayerInModel==True):\n","    model=putResizeLayerInModel(model)\n","  return model\n","\n","def loadVGGFaceModel(useResizeLayerInModel=False):\n","  model = loadAModel(basemodel=vggbaseModel(),nameOfWheights='vgg_face_weights.h5')\n","  model= Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n","  if(useResizeLayerInModel==True):\n","    model=putResizeLayerInModel(model)\n","  return model\n","\n","def loadOpenFaceModel(useResizeLayerInModel=False):\n","  model=loadAModel(basemodel=openFaceModel(),nameOfWheights='openface_weights.h5')\n","  if(useResizeLayerInModel==True):\n","    model=putResizeLayerInModel(model)\n","  return model\n","\n","def loadDeepFaceModel(useResizeLayerInModel=False):\n","  base_model=  loadAModel(basemodel=deepFaceModel(),nameOfWheights='VGGFace2_DeepFace_weights_val-0.9034.h5')\n","  base_model= Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n","  if(useResizeLayerInModel==True):\n","    base_model=putResizeLayerInModel(base_model)\n","  return base_model\n","\n","def loadDeepIDModel(useResizeLayerInModel=False):\n","  model= loadAModel(basemodel=deepIDModel(),nameOfWheights='deepid_keras_weights.h5')\n","  if(useResizeLayerInModel==True):\n","    model=putResizeLayerInModel(model)\n","  return model\n","\n","def loadArcFaceModel(useResizeLayerInModel=False):\n","  model= loadAModel(basemodel=arcFaceModel(),nameOfWheights='arcface_weights.h5')\n","  if(useResizeLayerInModel==True):\n","    model=putResizeLayerInModel(model)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fQ8asus0FMo"},"source":["df=checkPointDF[checkPointDF[\"image\"]!=\"\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CugVbjXN0FMp"},"source":["floatTypeColumns= [\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n","#  'Suitability',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian']\n","\n","for column in floatTypeColumns:\n","  # print(column)\n","  df[column] = df[column].astype(float)\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vk3-H69J0FMp"},"source":["def overviewOfInputData(startIndex: int, endIndex: int, data):\n","    \"\"\"\n","    The function plots some of the pictures.\n","    \n","    Arguments:\n","    startIndex: the index of the first pictue to be shown \n","    endIndex: the index of the last pictue to be shown \n","    data: this is the np array containing the pictures.\n","    \"\"\"\n","    fig = plt.figure(figsize=(20,20))\n","    for i in range(startIndex, endIndex+1):\n","        input_img = data[i]\n","        ax = fig.add_subplot(16,12,i+1)\n","        ax.imshow(input_img, cmap=plt.cm.gray)\n","        plt.xticks(np.array([]))\n","        plt.yticks(np.array([]))\n","        plt.tight_layout()\n","    plt.show()\n","\n","def showPicture(index:int, data ):\n","  \"\"\"\n","  The function plots the picture with the given index.\n","  \n","  Arguments:\n","  index: the index of the picture to be \n","  data: this is the np array containing the pictures.\n","  \"\"\"\n","  input_img = data[index] \n","  print (input_img.shape)\n","  plt.imshow(input_img)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0Vd7YNJ0FMp"},"source":["image_column=\"image\"\n","def applyFunctionToDataset(dataset, column, function):\n","  for index in dataset.index:\n","    img= function(dataset.loc[index][column]) \n","    dataset.at[index,column]=img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAIFldCS0FMq"},"source":["def resizeImage(image, height=160, width=160):\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image,size=[height,width])\n","    image=np.asarray(image)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JX6qws20FMq"},"source":["def flip_horizonally(image):\n","  # print(image.shape)\n","  image = tf.cast(image, tf.float32)\n","  flipped = tf.image.flip_left_right(image)\n","  flipped=np.asarray(flipped)\n","  return flipped\n","# plt.imshow( flip_horizonally(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dnXv-3X0FMq"},"source":["def translation(image, lowrange=5, highrange=20): \n","  # Store height and width of the image\n","  height = image.shape[0]\n","  width  = image.shape[1]\n","\n","  random_height_div= random.randint(lowrange, highrange)\n","  random_width_div = random.randint(lowrange, highrange)\n","  quarter_height, quarter_width = height / random_height_div, width / random_width_div\n","\n","  T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n","    \n","  # We use warpAffine to transform\n","  # the image using the matrix, T\n","  img_translation = cv2.warpAffine(image, T, (width, height))\n","  return img_translation\n","\n","# for i in range(10):\n","#   plot = plt.figure(i)\n","#   plt.imshow( translation(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-UhqONE0FMq"},"source":["def rotate_image(image, angle):\n","  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n","  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n","  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n","  return result\n","\n","def random_rotate_image(image, degree_range=10):\n","  # image = tf.cast(image, tf.float32)\n","  randomAngle = random.randint(-degree_range,degree_range)\n","  # print(image.shape)\n","  image =  rotate_image( image, randomAngle)\n","  return image\n","\n","# for i in range(4):\n","#   plot = plt.figure(i)\n","#   plt.imshow( random_rotate_image(image).astype(\"uint8\"))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbd-aBN40FMq"},"source":["def random_crop(image):\n","  cropped_image = tf.image.random_crop(\n","      image, size=[int(image.shape[0]-(image.shape[0]/5)),int(image.shape[1]-(image.shape[1]/5)), image.shape[2]])\n","  cropped_image = tf.image.resize(cropped_image,size=[image.shape[0], image.shape[1]])\n","\n","  cropped_image=np.asarray(cropped_image)\n","  return cropped_image\n","\n","# for i in range(10):\n","#   plot = plt.figure(i)\n","#   croppedimage=random_crop(image)\n","#   print(croppedimage.shape)\n","#   plt.imshow( croppedimage.astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1jUv_aX0FMq"},"source":["applyFunctionToDataset(df, image_column, resizeImage )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmROXMDM0FMr"},"source":["X= df[\"image\"]\n","Y= df.drop(\"image\", axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HuBGasBR0FMr"},"source":["# overviewOfInputData(0,2, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQZ8icB30FMr"},"source":["%cd /content/drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOdlvcAp0FMr"},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.3, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DaVK9-y00FMr"},"source":["df_train= y_train\n","lista=list(x_train)\n","df_train[\"image\"]= lista"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdDhtu_B0FMr"},"source":["df_train[\"augm_type\"]=\"None\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4J9uLHkQ0FMs"},"source":["# df_train.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pel5WeKa0FMs"},"source":["  # plt.imshow( df_train[\"image\"].iloc[0].astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8my_IoL50FMs"},"source":["currentDF=df_train.copy()\n","# chechpoint=df_train.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0LPnYPORi66"},"source":["del df_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjnU9ayt0FMs"},"source":["horizonalFlipDF= currentDF.copy()\n","applyFunctionToDataset(horizonalFlipDF, image_column, flip_horizonally )\n","horizonalFlipDF[\"augm_type\"]=\"HF\"\n","# plt.imshow( horizonalFlipDF[\"image\"].iloc[0].astype(\"uint8\"))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ksyJAe_Z0FMt"},"source":["currentDF= pd.concat([currentDF, horizonalFlipDF], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYeBcn-60FMt"},"source":["# currentDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xC3N-Q70FMt"},"source":["rotatedDF1=currentDF.copy()\n","rotatedDF2=currentDF.copy()\n","applyFunctionToDataset(rotatedDF1, image_column, random_rotate_image )\n","applyFunctionToDataset(rotatedDF2, image_column, random_rotate_image )\n","rotatedDF1[\"augm_type\"]=\"RO\"\n","rotatedDF2[\"augm_type\"]=\"RO\"\n","\n","# plt.imshow( rotatedDF1[\"image\"].iloc[0].astype(\"uint8\")) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYzD-BZv0FMt"},"source":["currentDF= pd.concat([currentDF, rotatedDF1, rotatedDF2], ignore_index=True)\n","# currentDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h812ib9t0FMt"},"source":["translationDF=horizonalFlipDF.copy()\n","randomCropping=horizonalFlipDF.copy()\n","\n","# translationDF_rotated=currentDF.copy()\n","# randomCropping_rotated=currentDF.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdmhoBBA0FMt"},"source":["applyFunctionToDataset(translationDF, image_column, translation )\n","applyFunctionToDataset(randomCropping, image_column, random_crop )\n","\n","# applyFunctionToDataset(translationDF_rotated, image_column, translation )\n","# applyFunctionToDataset(randomCropping_rotated, image_column, random_crop )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mp1K-Soi0FMt"},"source":["translationDF[\"augm_type\"]=translationDF[\"augm_type\"]+ \"-TR\"\n","randomCropping[\"augm_type\"]=randomCropping[\"augm_type\"]+ \"-RC\"\n","# translationDF_rotated[\"augm_type\"]=translationDF_rotated[\"augm_type\"]+ \"-TR\"\n","# randomCropping_rotated[\"augm_type\"]=randomCropping_rotated[\"augm_type\"]+ \"-RC\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jaGUxhD0FMt"},"source":["# currentDF= pd.concat([currentDF, translationDF, randomCropping, translationDF_rotated, randomCropping_rotated], ignore_index=True)\n","currentDF= pd.concat([currentDF, translationDF, randomCropping], ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGlF3jp_CWNA"},"source":["del horizonalFlipDF"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMFl3UTOCG1N"},"source":["del translationDF\n","del randomCropping\n","del rotatedDF1\n","del rotatedDF2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QGdOXQRClJy"},"source":["import gc\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJNwiR-HS0EW"},"source":["gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlnoBkyH0FMu"},"source":["def overviewOfInputData(startIndex: int, endIndex: int, dataframe, targetcolumn=\"image\"):\n","    \"\"\"\n","    The function plots some of the pictures.\n","    \n","    Arguments:\n","    startIndex: the index of the first pictue to be shown \n","    endIndex: the index of the last pictue to be shown \n","    data: this is the np array containing the pictures.\n","    \"\"\"\n","    fig = plt.figure(figsize=(20,20))\n","    for i in range(startIndex, endIndex+1):\n","        index= random.randint(0, dataframe.shape[0])\n","        input_img = dataframe[\"image\"].iloc[index]\n","        ax = fig.add_subplot(16,12,i+1)\n","        ax.imshow(input_img.astype(\"uint8\"))\n","        plt.xticks(np.array([]))\n","        plt.yticks(np.array([]))\n","        plt.tight_layout()\n","    plt.show()\n","\n","def showPicture(index:int, data ):\n","  \"\"\"\n","  The function plots the picture with the given index.\n","  \n","  Arguments:\n","  index: the index of the picture to be \n","  data: this is the np array containing the pictures.\n","  \"\"\"\n","  input_img = data[index] \n","  print (input_img.shape)\n","  plt.imshow(input_img)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lWsvdLl0FMu"},"source":["# # overviewOfInputData(0,35, currentDF)\n","# from deepface.commons import functions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIJSVFzIhdKi"},"source":["def cutLayersOut(model, numberOfLayersToCut, useResizeLayerInModel=True):\n","  newModel = tf.keras.Model( inputs= model.layers[0].input, \n","  outputs= model.layers[-numberOfLayersToCut].output\\\n","  )\n","  if(useResizeLayerInModel==True):\n","    newModel=putResizeLayerInModel(newModel)\n","  return newModel\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwycyEKs2cCF"},"source":["# # facenet= loadFaceNetModel()\n","# # vggface= loadVGGFaceModel()\n","# # openface=loadOpenFaceModel()\n","# # deepface=loadDeepFaceModel()\n","# # deepID=loadDeepIDModel()\n","# # arcFace=loadArcFaceModel()\n","\n","\n","facenet= loadFaceNetModel(useResizeLayerInModel=True)\n","vggface= loadVGGFaceModel(useResizeLayerInModel=True)   #Use this one\n","openface=loadOpenFaceModel(useResizeLayerInModel=True)\n","deepface=loadDeepFaceModel(useResizeLayerInModel=True)\n","deepID=loadDeepIDModel(useResizeLayerInModel=True)      #Use this one\n","arcFace=loadArcFaceModel(useResizeLayerInModel=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDT_uKOZidEQ"},"source":["cutFaceNet=cutLayersOut(facenet.layers[1], 3)\n","cutDeepId=cutLayersOut(deepID.layers[1], 8)\n","cutArcFace=cutLayersOut(arcFace.layers[1], 3)\n","cutvggface=cutLayersOut(vggface.layers[1], 1)\n","cutOpenFace=cutLayersOut(openface.layers[1], 3)\n","cutDeepFace=cutLayersOut(deepface.layers[1], 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYsFXINKEXkV"},"source":["# del facenet\n","# del vggface\n","# del openface\n","# del deepface\n","# del deepID\n","# del arcFace\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UtsM-VQC0FMu"},"source":["# image_column=\"image\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6he7cJdE-sre"},"source":["listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"] \n","def findFaceInImage(image,listWithFaceDetectors,grayscale = False, enforce_detection = True, align = True):\n","  managed_to_find_face=False\n","  for detector_backend in listWithFaceDetectors:\n","    try:\n","        img, region = functions.detect_face(img = image, detector_backend = detector_backend, grayscale = grayscale, enforce_detection = enforce_detection, align = align)\n","        #--------------------------\n","        if img.shape[0] == 0 or img.shape[1] == 0:\n","          if enforce_detection == True:\n","            raise ValueError(\"Detected face shape is \", img.shape,\". Consider to set enforce_detection argument to False.\")\n","          else: #restore base image\n","            img = base_img.copy()\n","        #--------------------------\n","\n","      #   img = functions.preprocess_face(img = image\n","      # , target_size=(input_shape_y, input_shape_x)\n","      # , enforce_detection = enforce_detection\n","      # , detector_backend = detector_backend\n","      # , align = align)\n","        managed_to_find_face=True\n","        img= resizeImage(image=img).astype(\"uint8\")\n","        return img\n","    except ValueError: \n","      continue\n","  if(managed_to_find_face==False):\n","    print(\"I COUNT NOT FIND THE FACE!!!!!\")\n","    plt.imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ld2vzYL-BqR0"},"source":["import time\n","from os import path\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import pickle\n","\n","from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID, DlibWrapper, ArcFace, Boosting\n","from deepface.commons import functions, realtime, distance as dst\n","from keras.preprocessing import image as image_keras_preprocessing\n","\n","#################\n","\n","def postProcesssing(img, grayscale=False,target_size=(160,160)):\n","  #post-processing\n","  if grayscale == True:\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","  img = cv2.resize(img, target_size)\n","  #TODO: resize causes transformation on base image, you should add black pixels to rezie it to target_size\n","\n","  img_pixels = image_keras_preprocessing.img_to_array(img)\n","  img_pixels = np.expand_dims(img_pixels, axis = 0)\n","  img_pixels /= 255 #normalize input in [0, 1]\n","  return img_pixels\n","\n","\n","def getFaceImages(images, listWithFaceDetectors=[\"ssd\", \"opencv\",\"mtcnn\",\"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True):\n","  #detect face in all images\n","  FRimages=list()\n","  for image in images: \n","    managed_to_find_face=False\n","    for detector_backend in listWithFaceDetectors:\n","      try:\n","          img, region = functions.detect_face(img = image, detector_backend = detector_backend, grayscale = grayscale, enforce_detection = enforce_detection, align = align)\n","          #--------------------------\n","          if img.shape[0] == 0 or img.shape[1] == 0:\n","            if enforce_detection == True:\n","              raise ValueError(\"Detected face shape is \", img.shape,\". Consider to set enforce_detection argument to False.\")\n","            else: #restore base image\n","              img = base_img.copy()\n","          #--------------------------\n","\n","        #   img = functions.preprocess_face(img = image\n","        # , target_size=(input_shape_y, input_shape_x)\n","        # , enforce_detection = enforce_detection\n","        # , detector_backend = detector_backend\n","        # , align = align)\n","          managed_to_find_face=True\n","          img= resizeImage(image=img).astype(\"uint8\")\n","          FRimages.append(img)\n","          break;\n","      except ValueError: \n","        continue\n","    if(managed_to_find_face==False):\n","      print(\"I COUNT NOT FIND THE FACE!!!!!\")\n","      plt.imshow(image)\n","  return FRimages\n","\n","def getSizeOfEmbedings(tempImage,model_list):\n","  sizeOfFinalinput=0;\n","  for model in model_list:\n","    input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","    img= postProcesssing(tempImage, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","    curentEmbedings = model.predict(img)[0].tolist()\n","    sizeOfFinalinput= sizeOfFinalinput+ len(curentEmbedings)\n","  return sizeOfFinalinput\n","\n","def getEmbedings(FRimages,model_list, sizeOfFinalInput):\n","  inputSize=(len(FRimages), sizeOfFinalInput)\n","  embedings=np.empty(inputSize)\n","  for index, image in enumerate(FRimages):\n","    image_embedgins= list()\n","    for model in model_list:\n","      try:\n","        input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","        img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","        curentEmbedings = model.predict(img)[0].tolist()\n","        image_embedgins.extend(curentEmbedings)\n","      except:\n","        print(\"i couldnt get embedings\")\n","        plt.imshow(image)\n","    npEmbedings=np.asarray(image_embedgins)\n","    embedings[index]=npEmbedings\n","  return embedings\n","\n","\n","def myRepresent(images,model_list , listWithFaceDetectors=[\"ssd\", \"opencv\",\"mtcnn\",\"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True):\n","  \"\"\"\n","  This function represents facial images as vectors.\n","  Parameters:\n","    img_path: exact image path, numpy array or based64 encoded images could be passed.\n","    model_name (string): VGG-Face, Facenet, OpenFace, DeepFace, DeepID, Dlib, ArcFace.\n","    model: Built deepface model. A face recognition model is built every call of verify function. You can pass pre-built face recognition model optionally if you will call verify function several times. Consider to pass model if you are going to call represent function in a for loop.\n","      model = DeepFace.build_model('VGG-Face')\n","    enforce_detection (boolean): If any face could not be detected in an image, then verify function will return exception. Set this to False not to have this exception. This might be convenient for low resolution images.\n","    detector_backend (string): set face detector backend as retinaface, mtcnn, opencv, ssd or dlib\n","  Returns:\n","    Represent function returns a multidimensional vector. The number of dimensions is changing based on the reference model. E.g. FaceNet returns 128 dimensional vector; VGG-Face returns 2622 dimensional vector.\n","  \"\"\"\n","  \n","  #detect face in all images\n","  FRimages=getFaceImages(images=images, listWithFaceDetectors=listWithFaceDetectors, grayscale=grayscale, enforce_detection = enforce_detection, align = align)\n","\n","\n","  tempImage=FRimages[0]\n","  sizeOfFinalinput=getSizeOfEmbedings(tempImage,model_list)\n","  print(\"sizeOfFinalinput \"+str(sizeOfFinalinput) )\n","\n","  embedings=getEmbedings(FRimages,model_list, sizeOfFinalInput=sizeOfFinalinput)\n","  return embedings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTe_J9-QEGoC"},"source":["gc.collect()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaPVU8i5Xcmp"},"source":["# with open(\"embedings.txt\", \"w\") as file_object:\n","#     # Append 'hello' at the end of file\n","#     file_object.write(\"this is the first line\\n\")\n","#     file_object.write(\"0 , something, something else\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob5F3HGjX8ZL"},"source":["# with open(\"embedings.txt\", \"r\") as file:\n","#     for last_line in file:\n","#         pass\n","\n","# startingIndex=int(last_line.split(\",\")[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUZNe6cSYcET"},"source":["# startingIndex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNIZmN0nLbbR"},"source":["\n","# # face_recognition_models=[facenet,vggface,openface, deepface,deepID,arcFace]\n","\n","# cutModelList=[cutFaceNet,cutDeepId ,cutArcFace]\n","# cutModelNames=[\"cutFaceNet\",\"cutDeepId\" ,\"cutArcFace\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-74BOnTg-oE"},"source":["df_test= y_test\n","lista=list(x_test)\n","df_test[\"image\"]= lista"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D53IDw_4Ymaz"},"source":["currentDF= df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEbvrsbW7Xf1"},"source":["len(list(currentDF[image_column]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rLI4keyg2cCF"},"source":["face_recognition_models=[facenet,vggface,openface, deepface,deepID, arcFace ]\n","cut_face_recognition_models=[cutFaceNet, cutvggface, cutOpenFace, cutDeepFace, cutDeepId, cutArcFace]\n","face_recognition_models_names=[\"facenet\",\"vggface\",\"openface\", \"deepface\",\"deepID\", \"arcFace\"]\n","cutModelNames=[\"cutFaceNet\", \"cutvggface\", \"cutOpenFace\", \"cutDeepFace\", \"cutDeepId\", \"cutArcFace\"]\n","\n","print(len(face_recognition_models))\n","print(len(cut_face_recognition_models))\n","print(len(face_recognition_models_names))\n","print(len(cutModelNames))\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX7L8kfnZdnZ"},"source":["startingIndex=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuyqU3e9X3Lu"},"source":["listofImages=list(currentDF[image_column])\n","with open(\"embedings_test.txt\", \"a\") as file:\n","  for index  in range(startingIndex, len(listofImages)):\n","    print(index)\n","    image= listofImages[index]\n","    image=image.astype(\"uint8\")\n","    image=findFaceInImage(image,listWithFaceDetectors=listWithFaceDetectors )\n","\n","    for model,cutModel,modelName, cutModelName in zip(face_recognition_models,cut_face_recognition_models, face_recognition_models_names, cutModelNames):\n","      try:\n","        # print(modelName, cutModelName)\n","        input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","        img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","        curentEmbedings = model.predict(img)[0].tolist()\n","        currentCut= cutModel.predict(img)[0].tolist()\n","        # print(str(index)+ \" aaaa \"+ modelName+\" bbbb \"+ str(curentEmbedings) +\" aaaa \" +cutModelName+ \"bbbb \" +str(currentCut)+\" \\n\")\n","        file.write(str(index)+ \" aaaa \"+ modelName+\" bbbb \"+ str(curentEmbedings) +\" aaaa \" +cutModelName+ \"bbbb \" +str(currentCut)+\"\\n\")\n","      except Exception as e:\n","        print(e)\n","        # print(\"i couldnt get embedings\")\n","        print(\"the index is \", index)\n","        plt.imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIUQvLMmFEjh"},"source":["# with open( r\"embedings.txt\", \"r\") as a_file:\n","#     i=0\n","#     for  line in a_file:\n","#       i=i+1\n","\n","# print(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufYsRw_XKhYB"},"source":["currentDF.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"25TKZf8sK2cw"},"source":["columnsToDrop= [ 'image']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sj_RE6hQKVHl"},"source":["currentDF= currentDF.drop(columnsToDrop, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyT_v4DwP3ow"},"source":["currentDF.to_csv('currentDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lV-iDudHrJIK"},"source":["import pandas as pd\n","import numpy as np\n","face_recognition_models_names=[\"facenet\",\"vggface\",\"openface\", \"deepface\",\"deepID\", \"arcFace\"]\n","cutModelNames=[\"cutFaceNet\", \"cutvggface\", \"cutOpenFace\", \"cutDeepFace\", \"cutDeepId\", \"cutArcFace\"]\n","\n","columns= cutModelNames+ face_recognition_models_names\n","embedingsDF = pd.DataFrame(columns = columns )\n","\n","pdIndex=0\n","dic = dict()\n","\n","numberOfLinesToSkip=2\n","with open( r\"/content/drive/MyDrive/embedings_test.txt\", \"r\") as a_file:\n","    skipIndex=0\n","    plainIndex=0;\n","    for  line in a_file:\n","      # print(plainIndex)\n","      if(skipIndex<numberOfLinesToSkip):\n","          skipIndex=skipIndex+1\n","          continue\n","      parts=line.split(\"aaaa\")\n","      index=int(parts[0])\n","      parts=parts[1:]\n","      if(pdIndex!=index):\n","          embedingsDF = embedingsDF.append(dic, ignore_index=True)\n","          pdIndex = pdIndex+1\n","          dic = dict()\n","      for part in parts:\n","          komathkia= part.split(\"bbbb\")\n","          name= komathkia[0].strip()\n","          strNumbers=komathkia[1]\n","          strNumbers = strNumbers.replace(\"[\", \"\")\n","          strNumbers = strNumbers.replace(\"]\", \"\")\n","          strNumbers=strNumbers.split(\",\")\n","          embedings=list()\n","          for strnumber in strNumbers:\n","              embedings.append(float(strnumber))\n","          dic[name]=embedings\n","      plainIndex=plainIndex+1\n","\n","\n","embedingsDF = embedingsDF.append(dic, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aw2eZ3iaQzgI"},"source":["import pandas as pd\n","currentDF = pd.read_csv ('/content/drive/MyDrive/currentDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSB2iRyprdG8"},"source":["toSaceDF= pd.concat([currentDF.reset_index(drop=True),embedingsDF.reset_index(drop=True)], axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPZMadJ3Q9VV"},"source":["toSaceDF.to_csv('/content/drive/MyDrive/toSaceDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d1WsEFuit5R"},"source":["with open(\"embedings.txt\", \"a\") as file:\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EcBv8BbVZoP"},"source":["import pandas as pd\n","currentDF = pd.read_csv ('/content/drive/MyDrive/toSaceDF.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AyVMUEDVcpx"},"source":["type(currentDF[\"facenet\"][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"31eLzoSa1zp_"},"source":["# embedingsDF = pd.DataFrame(columns = cutModelNames)\n","# cutEmbedingsDF = pd.DataFrame(columns = face_recognition_models_names)\n","# for index, image  in enumerate(list(currentDF[image_column])):\n","#   print(index)\n","#   image=image.astype(\"uint8\")\n","#   image=findFaceInImage(image,listWithFaceDetectors=listWithFaceDetectors )\n","#   image_embedgins= dict()\n","#   image_cut_embedgins= dict()\n","\n","#   for model,cutModel,modelName, cutModelName in zip(face_recognition_models,cut_face_recognition_models, face_recognition_models_names, cutModelNames):\n","#     try:\n","#       input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","#       img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","#       curentEmbedings = model.predict(img)[0].tolist()\n","#       currentCut= cutModel.predict(img)[0].tolist()\n","#       image_embedgins[modelName] =curentEmbedings\n","#       image_cut_embedgins[cutModelName] =currentCut\n","\n","#     except Exception as e:\n","#       print(e)\n","#       # print(\"i couldnt get embedings\")\n","#       print(\"the index is \", index)\n","#       plt.imshow(image)\n","\n","#   embedingsDF = embedingsDF.append(image_embedgins, ignore_index=True)\n","#   cutEmbedingsDF = cutEmbedingsDF.append(image_cut_embedgins, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkrGpNY1ewS1"},"source":["toSaceDF= pd.concat([currentDF.reset_index(drop=True),embedingsDF.reset_index(drop=True)], axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"309w-TM8g-TI"},"source":["image_column=\"image\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NzFx4DuhNun"},"source":["def addEmbedingsInDF(currentDF,listWithFaceDetectors\n","                     ,face_recognition_models, \n","                     face_recognition_models_names):\n","  embedingsDF = pd.DataFrame(columns = face_recognition_models_names)\n","  for index, image  in enumerate(list(currentDF[image_column])):\n","    print(index)\n","    image=image.astype(\"uint8\")\n","    image=findFaceInImage(image,listWithFaceDetectors=listWithFaceDetectors )\n","    image_embedgins= dict()\n","    for model,modelName in zip(face_recognition_models,face_recognition_models_names):\n","      try:\n","        input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","        img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","        curentEmbedings = model.predict(img)[0].tolist()\n","        image_embedgins[modelName] =curentEmbedings\n","      except Exception as e:\n","        print(e)\n","        # print(\"i couldnt get embedings\")\n","        print(\"the index is \", index)\n","        plt.imshow(image)\n","\n","    embedingsDF = embedingsDF.append(image_embedgins, ignore_index=True)\n","  toSaceDF= pd.concat([embedingsDF,currentDF], axis=1)\n","  return toSaceDF\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIzcIK2Dhyap"},"source":["# face_recognition_models=[facenet,vggface,openface, deepface,deepID, arcFace ]\n","# face_recognition_models_names=[\"facenet\",\"vggface\",\"openface\", \"deepface\",\"deepID\", \"arcFace\"]\n","# listWithFaceDetectors=[\"ssd\", \"opencv\",\"mtcnn\",\"dlib\", \"retinaface\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fny4uVzinnNy"},"source":["df_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSE1HFDxh8Zt"},"source":["# toSaceDF_test= addEmbedingsInDF(currentDF=df_test,\n","#                                 listWithFaceDetectors=listWithFaceDetectors\n","#                      ,face_recognition_models=face_recognition_models, \n","#                      face_recognition_models_names=face_recognition_models_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm0Gf1lfp-QH"},"source":["embedingsDF = pd.DataFrame(columns = face_recognition_models_names+cutModelNames )\n","for index, image  in enumerate(list(df_test[image_column])):\n","  print(index)\n","  image=image.astype(\"uint8\")\n","  image=findFaceInImage(image,listWithFaceDetectors=listWithFaceDetectors )\n","  image_embedgins= dict()\n","\n","  for model,cutModel,modelName, cutModelName in zip(face_recognition_models,cut_face_recognition_models, face_recognition_models_names, cutModelNames):\n","    try:\n","      input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","      img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","      curentEmbedings = model.predict(img)[0].tolist()\n","      curentEmbedings_cut = cutModel.predict(img)[0].tolist()\n","      image_embedgins[modelName] =curentEmbedings\n","      image_embedgins[cutModelName] =curentEmbedings_cut\n","    except Exception as e:\n","      print(e)\n","      # print(\"i couldnt get embedings\")\n","      print(\"the index is \", index)\n","      plt.imshow(image)\n","  embedingsDF = embedingsDF.append(image_embedgins, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eT11DzBUjgqB"},"source":["for (columnName, columnData) in embedingsDF.iteritems():\n","   print('Colunm Name : ', columnName)\n","   print('Column Contents : ', columnData.isnull().values.any())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mM2AUj8nwMw"},"source":["df_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7m1kfzLr8cQ"},"source":["embedingsDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tw65TP1vsHd8"},"source":["toSaceDF_test= pd.concat([df_test.reset_index(drop=True),embedingsDF.reset_index(drop=True)], axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrcrH8HNsS0T"},"source":["toSaceDF_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m64Vkk2tmHAR"},"source":["for (columnName, columnData) in toSaceDF_test.iteritems():\n","   print('Colunm Name : ', columnName)\n","   print('Column Contents : ', columnData.isnull().values.any())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jx0G8dSQe71S"},"source":["toSaceDF_test.to_csv('toSaceDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shBmmeWXgcGi"},"source":["len(toSaceDF_test[\"facenet\"].isna()==True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2-6wFPspsIV"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kr7DcoJK1tfW"},"source":["embedingsDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbgHASLX1Qlu"},"source":[" FRimages= getFaceImages(images=x_train_final, listWithFaceDetectors=[\"opencv\",\"mtcnn\",\"ssd\", \"dlib\", \"retinaface\"], grayscale=False, enforce_detection = True, align = True)\n","    for index, model in enumerate(face_recognition_models):\n","      model_list=[model]\n","      model_name=face_recognition_models_names[index]\n","\n","      tempImage=FRimages[0]\n","      sizeOfFinalinput=getSizeOfEmbedings(tempImage,model_list)\n","      # print(\"sizeOfFinalinput \"+str(sizeOfFinalinput) )\n","      embedings=getEmbedings(FRimages,model_list, sizeOfFinalInput=sizeOfFinalinput)\n","      currentDF\n","      saveEmbedingsForModel(embednings=embedings,desiredOutputs=dic[\"y\"] , augment_type=key, model_name= model_name,dir_type=dir_type)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTeI3qQYDIzj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SN6N1lgagfjk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9T6gj7o5gfnf"},"source":["embedingsDF = pd.DataFrame(columns = face_recognition_models_names)\n","for index, image  in enumerate(list(currentDF[image_column])):\n","  print(index)\n","  image=image.astype(\"uint8\")\n","  image=findFaceInImage(image,listWithFaceDetectors=listWithFaceDetectors )\n","  image_embedgins= dict()\n","  for model,modelName in zip(face_recognition_models,face_recognition_models_names):\n","    try:\n","      input_shape =  input_shape_x, input_shape_y= functions.find_input_shape(model)\n","      img= postProcesssing(image, grayscale=False,target_size=(input_shape_y, input_shape_x))\n","      curentEmbedings = model.predict(img)[0].tolist()\n","      image_embedgins[modelName] =curentEmbedings\n","    except Exception as e:\n","      print(e)\n","      # print(\"i couldnt get embedings\")\n","      print(\"the index is \", index)\n","      plt.imshow(image)\n","\n","  embedingsDF = embedingsDF.append(image_embedgins, ignore_index=True)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7pEz6FKMj8h"},"source":["# testDF= pd.read_csv(\"/content/drive/MyDrive/toSaceDF_test.csv\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sz0dJ8VmG6xD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q70MGFCiHREF"},"source":["Mix old and new dataset."]},{"cell_type":"code","metadata":{"id":"ZcvToC_hHFd9"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3MBGzZPHFeA"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0mm8tGTSHFeB"},"source":["!ls drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kF_lEsSTHFeC"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-female.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NTV5s8yIAh9"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVvUAm3mHFeD"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OP0f6_fMHFeE"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6IheZfqI46K"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dquQWO6I9z6"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id_male\",\n"," 'ID':\"imageName_male\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness_male\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness_male\",\n"," \"The person's race is:\": \"subjectEthicity_male\",\n"," \"The person's skin color is:\": \"subjectSkinColour_male\",\n"," 'What is the gender of the depicted person?':\"subjectGender_male\",\n"," 'What is the age of the depicted person?':\"subjectAge_male\",\n"," 'Which state do you currently reside in?':\"annotator_state_male\",\n"," 'You are currently:':\"annotator_employment_male\",\n"," 'What is your educational level?': \"annotator_educationLevel_male\",\n"," 'What is your gender?': \"annotator_gender_male\",\n"," 'What is your race?': \"annotator_race_male\",\n"," 'What is your age?': \"annotator_age_male\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1yxT3m_KeH0"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7R-yekMKK6Yk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHzXFIM1K0db"},"source":["df_males=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppxWBDVLLIt-"},"source":["list(df_males.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_Psc5rhKxeE"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-male.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kuz9xrdQKxeE"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkoOLfYCKxeF"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLGk0wIiKxeG"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JvZqkD-HKxeH"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEZ7RTJhKxeH"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id_female\",\n"," 'ID':\"imageName_female\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness_female\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness_female\",\n"," \"The person's race is:\": \"subjectEthicity_female\",\n"," \"The person's skin color is:\": \"subjectSkinColour_female\",\n"," 'What is the gender of the depicted person?':\"subjectGender_female\",\n"," 'What is the age of the depicted person?':\"subjectAge_female\",\n"," 'Which state do you currently reside in?':\"annotator_state_female\",\n"," 'You are currently:':\"annotator_employment_female\",\n"," 'What is your educational level?': \"annotator_educationLevel_female\",\n"," 'What is your gender?': \"annotator_gender_female\",\n"," 'What is your race?': \"annotator_race_female\",\n"," 'What is your age?': \"annotator_age_female\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oX3tAcaKxeI"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8nHy-CKLSRv"},"source":["df_female=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOM2Ra6TLU_K"},"source":["df_female= df_female.rename(columns={\n"," 'imageName_female':\"imageName\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZKFXM0aeNFzi"},"source":["df_males= df_males.rename(columns={\n"," 'imageName_male':\"imageName\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zV4J4TWNJ9g"},"source":["list(df_males.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MNiIseiHNNTU"},"source":["mergedDF=pd.merge(df_female,df_males,on='imageName')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"COtYyyLBNXdK"},"source":["print(df_males.shape)\n","print(df_female.shape)\n","print(mergedDF.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAq4BhSLQMZd"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlCYHTFaQi6g"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ll_7Br-3QaNv"},"source":["mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"1 - Not at all Attractive\", 'subjectAttractiveness_female'] = 1\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"2 - Non Attractive\", 'subjectAttractiveness_female'] = 2\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"3 - Somewhat non Attractive\", 'subjectAttractiveness_female'] = 3\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"4 - Neutral\", 'subjectAttractiveness_female'] = 4\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"5 - Somewhat Attractive\", 'subjectAttractiveness_female'] = 5\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"6 - Attractive\", 'subjectAttractiveness_female'] = 6\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"7 - Extremely Attractive\", 'subjectAttractiveness_female'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Id3uQnquRZBx"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S29ojtv3Telp"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FV5eDLz2Telz"},"source":["mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"1 - Not at all Attractive\", 'subjectAttractiveness_male'] = 1\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"2 - Non Attractive\", 'subjectAttractiveness_male'] = 2\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"3 - Somewhat non Attractive\", 'subjectAttractiveness_male'] = 3\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"4 - Neutral\", 'subjectAttractiveness_male'] = 4\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"5 - Somewhat Attractive\", 'subjectAttractiveness_male'] = 5\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"6 - Attractive\", 'subjectAttractiveness_male'] = 6\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"7 - Extremely Attractive\", 'subjectAttractiveness_male'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TltQzXKkTel0"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyzJ-YwTUEWw"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlRSVzOoTy8W"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjaPd9ENTy8Y"},"source":["mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"1 - Not at all Trustworthy\", 'subjectTrustworthyness_female'] = 1\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"2 - Non Trustworthy\", 'subjectTrustworthyness_female'] = 2\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"3 - Somewhat non Trustworthy\", 'subjectTrustworthyness_female'] = 3\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"4 - Neutral\", 'subjectTrustworthyness_female'] = 4\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"5 - Somewhat Trustworthy\", 'subjectTrustworthyness_female'] = 5\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"6 - Trustworthy\", 'subjectTrustworthyness_female'] = 6\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"7 - Extremely Trustworthy\", 'subjectTrustworthyness_female'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPRMcLk9Ty8Z"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVjsYUoYUmc8"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XnOTMu_UmdN"},"source":["mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"1 - Not at all Trustworthy\", 'subjectTrustworthyness_male'] = 1\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"2 - Non Trustworthy\", 'subjectTrustworthyness_male'] = 2\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"3 - Somewhat non Trustworthy\", 'subjectTrustworthyness_male'] = 3\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"4 - Neutral\", 'subjectTrustworthyness_male'] = 4\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"5 - Somewhat Trustworthy\", 'subjectTrustworthyness_male'] = 5\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"6 - Trustworthy\", 'subjectTrustworthyness_male'] = 6\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"7 - Extremely Trustworthy\", 'subjectTrustworthyness_male'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhZV4oZKUmdO"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"meiNkZs0UwLI"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUlz6hp3VFqT"},"source":["list(np.unique(mergedDF[\"subjectEthicity_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zQle2WaVFqU"},"source":["mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Asian\", 'subjectEthicity_female'] = \"A\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Black\", 'subjectEthicity_female'] = \"B\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Latino/a\", 'subjectEthicity_female'] = \"L\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"White\", 'subjectEthicity_female'] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xgwf1UGoVFqV"},"source":["list(np.unique(mergedDF[\"subjectEthicity_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSkQgCXgViNI"},"source":["list(np.unique(mergedDF[\"subjectEthicity_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHQsucHuViNS"},"source":["mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Asian\", 'subjectEthicity_male'] = \"A\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Black\", 'subjectEthicity_male'] = \"B\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Latino/a\", 'subjectEthicity_male'] = \"L\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"White\", 'subjectEthicity_male'] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbLq7RDwViNT"},"source":["list(np.unique(mergedDF[\"subjectEthicity_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60YXUEBAVqcn"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7cKEXp5V4O2"},"source":["targetColumn=\"subjectGender_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CpDH7hsV4O6"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCm56fPvV4O6"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_weFHg0XLT4"},"source":["targetColumn=\"subjectGender_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyuEqPqoXLT5"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anriaQzhXLT5"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nKJ21vVXPml"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuOibhAxXho1"},"source":["targetColumn=\"annotator_gender_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVpJt6qgXho3"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEXRF3bFXho4"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vgpHiE6Xpxg"},"source":["targetColumn=\"annotator_gender_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q63ivGFtXpxi"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2Y5s1s_Xpxj"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWAAUjBNX7HM"},"source":["mergedDF.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ivQib3FXv8m"},"source":["targetColumn=\"annotator_race_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IwlZCLyXv8n"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Asian\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Black\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Latino/a\", targetColumn] = \"L\"\n","mergedDF.loc[mergedDF[targetColumn]==\"White\", targetColumn] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQYrh9cNXv8o"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H79-NgT9YJ4x"},"source":["targetColumn=\"annotator_race_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezn9t74SYJ4y"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Asian\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Black\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Latino/a\", targetColumn] = \"L\"\n","mergedDF.loc[mergedDF[targetColumn]==\"White\", targetColumn] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzRO6B1HYJ4y"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wig9J3HhbvCm"},"source":["def turnColumnsToFloat(givenDF):\n","  for column in givenDF.columns:\n","    try:\n","      givenDF[column]=givenDF[column].astype(np.float32)\n","    except: \n","      print(\"column \", column, \" is not a number \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N7xroVfycJjI"},"source":["turnColumnsToFloat(mergedDF)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJ4kLGx5dAy_"},"source":["import random \n","def generateRandomNumber( minimum=0, maximum=10):\n","  return random.uniform(minimum, maximum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFzDtUuleD1C"},"source":["def pickAtRandom(lista):\n","  return random.choice(lista)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAmuSZP2dOPl"},"source":["generateRandomNumber()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zu96bJ8AZZHA"},"source":["randomDF= pd.DataFrame()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7B1Rt4fZkNs"},"source":["numberOfRows=df_female.shape[0]\n","\n","for column in df_female.columns:\n","  if(column== \"imageName\"):\n","    randomDF[column]=df_female[column]\n","  else:\n","    newColumn=column.split(\"female\")[0]\n","    newColumn=newColumn+\"random\"\n","    if (str(mergedDF.dtypes[column])==\"object\"):\n","      items= list(np.unique(mergedDF[column]))\n","      listOfItems=list()\n","      for index in range(numberOfRows):\n","        listOfItems.append(pickAtRandom(items)) \n","      randomDF[newColumn]=  listOfItems\n","    else: \n","      maximum=max(mergedDF[column])\n","      minimum= min(mergedDF[column])\n","      listOfNumbers=np.empty(shape=numberOfRows)\n","      for index in range(numberOfRows):\n","        listOfNumbers[index]=generateRandomNumber(maximum=maximum, minimum=minimum) \n","      randomDF[newColumn]=  listOfNumbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFaeP6DZagtz"},"source":["randomDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5QuGEV2gFRY"},"source":["randomDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhADlAPXf8da"},"source":["mergedDF=pd.merge(mergedDF,randomDF,on='imageName')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZTh3MeAgXPo"},"source":["mergedDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAtrTdHogaoC"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bvrd4rZMacJA"},"source":["df_female.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H96l7cLwe22T"},"source":["randomDF"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-jE8AVfNdSS"},"source":["df = pd.read_csv (r'/content/drive/MyDrive/toSaceDF.csv')\n","test_df=pd.read_csv (r'/content/drive/MyDrive/toSaceDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifMhl0ZstmT8"},"source":["df= df.drop(['Unnamed: 0.1'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UADFflvvt7P5"},"source":["df = df.rename(columns={'Unnamed: 0': 'id'})\n","test_df = test_df.rename(columns={'Unnamed: 0': 'id'})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3Vxu2l4OjUn"},"source":["list(test_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZYKjNNmOvcy"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8FEogupOPoH"},"source":["mergedDF= mergedDF.rename(columns={\n"," 'imageName':\"Model\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSg2r7-LOMkr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSb14zQlPOFC"},"source":["newDF=pd.merge(df,mergedDF,on='Model')\n","newTestDF=pd.merge(test_df,mergedDF,on='Model')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxPf1EaaPOFp"},"source":["print(mergedDF.shape)\n","\n","print(df.shape)\n","print(newDF.shape)\n","\n","print(test_df.shape)\n","print(newTestDF.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kz8vcfsRgsaW"},"source":["newDF"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNrXEtZNPhYz"},"source":["some= newDF[\"Model\"]==df[\"Model\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uO55YVW0Pzwd"},"source":["newDF[some][\"annotator_race_random\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSvtss6YP_LZ"},"source":["newDF"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pD5D8UlUQFjp"},"source":["newDF.to_csv('/content/drive/MyDrive/final_train_dataset.csv')\n","newTestDF.to_csv('/content/drive/MyDrive/final_test_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvC99QPzg4aL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e0aGFezZKofA"},"source":["Mix old and new dataset."]},{"cell_type":"code","metadata":{"id":"SVK_jb2ZKofJ"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ru2KwxywKofL"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aylpG63EKofL"},"source":["!ls drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybDLiSKEKofM"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-female.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XcmV_jm0KofN"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsMlQhcPKofN"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtN9RPpuKofO"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jo5oIcvzKofO"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnjBkfAGKofP"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id_male\",\n"," 'ID':\"imageName_male\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness_male\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness_male\",\n"," \"The person's race is:\": \"subjectEthicity_male\",\n"," \"The person's skin color is:\": \"subjectSkinColour_male\",\n"," 'What is the gender of the depicted person?':\"subjectGender_male\",\n"," 'What is the age of the depicted person?':\"subjectAge_male\",\n"," 'Which state do you currently reside in?':\"annotator_state_male\",\n"," 'You are currently:':\"annotator_employment_male\",\n"," 'What is your educational level?': \"annotator_educationLevel_male\",\n"," 'What is your gender?': \"annotator_gender_male\",\n"," 'What is your race?': \"annotator_race_male\",\n"," 'What is your age?': \"annotator_age_male\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqbMm6n0KofQ"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUs_eBB_KofQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A88dKucZKofR"},"source":["df_males=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuPJp_OLKofR"},"source":["list(df_males.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvAVlaYEKofR"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-male.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZCSQ5wiKofS"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXZ39hm_KofS"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wncHA_prKofS"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4abUItnQKofT"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6M5mhk8dKofT"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id_female\",\n"," 'ID':\"imageName_female\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness_female\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness_female\",\n"," \"The person's race is:\": \"subjectEthicity_female\",\n"," \"The person's skin color is:\": \"subjectSkinColour_female\",\n"," 'What is the gender of the depicted person?':\"subjectGender_female\",\n"," 'What is the age of the depicted person?':\"subjectAge_female\",\n"," 'Which state do you currently reside in?':\"annotator_state_female\",\n"," 'You are currently:':\"annotator_employment_female\",\n"," 'What is your educational level?': \"annotator_educationLevel_female\",\n"," 'What is your gender?': \"annotator_gender_female\",\n"," 'What is your race?': \"annotator_race_female\",\n"," 'What is your age?': \"annotator_age_female\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucxJJZczKofT"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTbLGU4rKofT"},"source":["df_female=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLNChtFiKofU"},"source":["df_female= df_female.rename(columns={\n"," 'imageName_female':\"imageName\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifnfiDcCKofU"},"source":["df_males= df_males.rename(columns={\n"," 'imageName_male':\"imageName\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8bW7bjHKofU"},"source":["list(df_males.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LEElqtw-KofV"},"source":["mergedDF=pd.merge(df_female,df_males,on='imageName')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWxAlN9MKofV"},"source":["print(df_males.shape)\n","print(df_female.shape)\n","print(mergedDF.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rLtdr1UMKofV"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMbf_flyKofV"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwcQOh4FKofW"},"source":["mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"1 - Not at all Attractive\", 'subjectAttractiveness_female'] = 1\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"2 - Non Attractive\", 'subjectAttractiveness_female'] = 2\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"3 - Somewhat non Attractive\", 'subjectAttractiveness_female'] = 3\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"4 - Neutral\", 'subjectAttractiveness_female'] = 4\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"5 - Somewhat Attractive\", 'subjectAttractiveness_female'] = 5\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"6 - Attractive\", 'subjectAttractiveness_female'] = 6\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_female\"]==\"7 - Extremely Attractive\", 'subjectAttractiveness_female'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YTbBQZaKofW"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOpiMGaHKofW"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFbeJO1CKofW"},"source":["mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"1 - Not at all Attractive\", 'subjectAttractiveness_male'] = 1\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"2 - Non Attractive\", 'subjectAttractiveness_male'] = 2\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"3 - Somewhat non Attractive\", 'subjectAttractiveness_male'] = 3\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"4 - Neutral\", 'subjectAttractiveness_male'] = 4\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"5 - Somewhat Attractive\", 'subjectAttractiveness_male'] = 5\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"6 - Attractive\", 'subjectAttractiveness_male'] = 6\n","mergedDF.loc[mergedDF[\"subjectAttractiveness_male\"]==\"7 - Extremely Attractive\", 'subjectAttractiveness_male'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14XydxjOKofW"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIGqqto-KofX"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DN7Jd7S1KofX"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BAJu2TFKofX"},"source":["mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"1 - Not at all Trustworthy\", 'subjectTrustworthyness_female'] = 1\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"2 - Non Trustworthy\", 'subjectTrustworthyness_female'] = 2\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"3 - Somewhat non Trustworthy\", 'subjectTrustworthyness_female'] = 3\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"4 - Neutral\", 'subjectTrustworthyness_female'] = 4\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"5 - Somewhat Trustworthy\", 'subjectTrustworthyness_female'] = 5\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"6 - Trustworthy\", 'subjectTrustworthyness_female'] = 6\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_female\"]==\"7 - Extremely Trustworthy\", 'subjectTrustworthyness_female'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjfFc9kkKofX"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlMBxW8_KofY"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGiMgL6iKofY"},"source":["mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"1 - Not at all Trustworthy\", 'subjectTrustworthyness_male'] = 1\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"2 - Non Trustworthy\", 'subjectTrustworthyness_male'] = 2\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"3 - Somewhat non Trustworthy\", 'subjectTrustworthyness_male'] = 3\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"4 - Neutral\", 'subjectTrustworthyness_male'] = 4\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"5 - Somewhat Trustworthy\", 'subjectTrustworthyness_male'] = 5\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"6 - Trustworthy\", 'subjectTrustworthyness_male'] = 6\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness_male\"]==\"7 - Extremely Trustworthy\", 'subjectTrustworthyness_male'] = 7\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs6x_l_0KofY"},"source":["list(np.unique(mergedDF[\"subjectTrustworthyness_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Hoy2o6QKofY"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrzGm-hGKofY"},"source":["list(np.unique(mergedDF[\"subjectEthicity_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHdG4YknKofZ"},"source":["mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Asian\", 'subjectEthicity_female'] = \"A\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Black\", 'subjectEthicity_female'] = \"B\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"Latino/a\", 'subjectEthicity_female'] = \"L\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_female\"]==\"White\", 'subjectEthicity_female'] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"phctcYRdKofZ"},"source":["list(np.unique(mergedDF[\"subjectEthicity_female\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fj33y2tiKofZ"},"source":["list(np.unique(mergedDF[\"subjectEthicity_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_JdiGIXKofZ"},"source":["mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Asian\", 'subjectEthicity_male'] = \"A\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Black\", 'subjectEthicity_male'] = \"B\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"Latino/a\", 'subjectEthicity_male'] = \"L\"\n","mergedDF.loc[mergedDF[\"subjectEthicity_male\"]==\"White\", 'subjectEthicity_male'] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vGelxXnKofZ"},"source":["list(np.unique(mergedDF[\"subjectEthicity_male\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l15azExvKofa"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjG-eAqjKofa"},"source":["targetColumn=\"subjectGender_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd_WrRYLKofa"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQQgKJRdKofa"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WF5OUUuwKofa"},"source":["targetColumn=\"subjectGender_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0epzcpWKofb"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"31VPK6z0Kofb"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTUT4sC4Kofb"},"source":["mergedDF.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"72vuflE-Kofb"},"source":["targetColumn=\"annotator_gender_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTu0oIqgKofb"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rekY-AwZKofc"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dh9U_-MTKofc"},"source":["targetColumn=\"annotator_gender_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1ZC01NxKofc"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4BVv9jzKofc"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIdg2So2Kofc"},"source":["mergedDF.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWoqui7WKofc"},"source":["targetColumn=\"annotator_race_female\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iz-l7QrcKofd"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Asian\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Black\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Latino/a\", targetColumn] = \"L\"\n","mergedDF.loc[mergedDF[targetColumn]==\"White\", targetColumn] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8VP_1DwKofd"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chf-vQpsKofd"},"source":["targetColumn=\"annotator_race_male\"\n","list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Zx11KuRKofd"},"source":["mergedDF.loc[mergedDF[targetColumn]==\"Asian\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Black\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Latino/a\", targetColumn] = \"L\"\n","mergedDF.loc[mergedDF[targetColumn]==\"White\", targetColumn] = \"W\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkxEuB_7Kofd"},"source":["list(np.unique(mergedDF[targetColumn]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpIuN6IlKofe"},"source":["def turnColumnsToFloat(givenDF):\n","  for column in givenDF.columns:\n","    try:\n","      givenDF[column]=givenDF[column].astype(np.float32)\n","    except: \n","      print(\"column \", column, \" is not a number \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3KffVK1Kofe"},"source":["turnColumnsToFloat(mergedDF)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRR4gUFzKofe"},"source":["import random \n","def generateRandomNumber( minimum=0, maximum=10):\n","  return random.uniform(minimum, maximum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnbFf0rrKofe"},"source":["def pickAtRandom(lista):\n","  return random.choice(lista)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrT26pzzKofe"},"source":["generateRandomNumber()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ld2Z2A84Kofe"},"source":["randomDF= pd.DataFrame()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"goi8rGSJKoff"},"source":["numberOfRows=df_female.shape[0]\n","\n","for column in df_female.columns:\n","  if(column== \"imageName\"):\n","    randomDF[column]=df_female[column]\n","  else:\n","    newColumn=column.split(\"female\")[0]\n","    newColumn=newColumn+\"random\"\n","    if (str(mergedDF.dtypes[column])==\"object\"):\n","      items= list(np.unique(mergedDF[column]))\n","      listOfItems=list()\n","      for index in range(numberOfRows):\n","        listOfItems.append(pickAtRandom(items)) \n","      randomDF[newColumn]=  listOfItems\n","    else: \n","      maximum=max(mergedDF[column])\n","      minimum= min(mergedDF[column])\n","      listOfNumbers=np.empty(shape=numberOfRows)\n","      for index in range(numberOfRows):\n","        listOfNumbers[index]=generateRandomNumber(maximum=maximum, minimum=minimum) \n","      randomDF[newColumn]=  listOfNumbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7Z1dkE-Koff"},"source":["randomDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqgWpclhKoff"},"source":["randomDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"et7wgge2Koff"},"source":["mergedDF=pd.merge(mergedDF,randomDF,on='imageName')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kR-JGx9Koff"},"source":["mergedDF.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LC0L8rGdKofg"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eeHPn7ZkKofg"},"source":["df_female.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hiOVaBtzKofg"},"source":["randomDF"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yg9t35LkKofg"},"source":["df = pd.read_csv (r'/content/drive/MyDrive/toSaceDF.csv')\n","test_df=pd.read_csv (r'/content/drive/MyDrive/toSaceDF_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfcyDHDoKofg"},"source":["df= df.drop(['Unnamed: 0.1'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yH82TP6SKofh"},"source":["df = df.rename(columns={'Unnamed: 0': 'id'})\n","test_df = test_df.rename(columns={'Unnamed: 0': 'id'})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy7SABNoKofh"},"source":["list(test_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_oB8xgTKofh"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sV7DquWUKofh"},"source":["mergedDF= mergedDF.rename(columns={\n"," 'imageName':\"Model\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K6PvygtXKtg9"},"source":["# CreateMultipleDataset[link text](**https://**) **bold text**"]},{"cell_type":"code","metadata":{"id":"scgWfSrwK8h9"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8AQChRM2K8h-"},"source":["#IMPORTS\n","from keras.utils.np_utils import to_categorical\n","# import keras\n","import pandas as pd\n","import numpy as np\n","import random\n","# import brewer2mpl\n","import sys\n","import warnings\n","from google.colab import files\n","import os\n","import tensorflow as tf\n","import keras_preprocessing\n","from keras_preprocessing import image\n","from keras_preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import pathlib\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import regularizers\n","Heinitializer = tf.keras.initializers.HeNormal()\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","import time\n","\n","from IPython import display\n","\n","\n","\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pz_rlhKMK8h-"},"source":["!ls drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3NCweN-K8h-"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-female.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FotgD76eK8h-"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcybZWUPK8h-"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TASDQTY9K8h_"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG5XgafaK8h_"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVffALgJK8h_"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id\",\n"," 'ID':\"imageName\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness\",\n"," \"The person's race is:\": \"subjectEthicity\",\n"," \"The person's skin color is:\": \"subjectSkinColour\",\n"," 'What is the gender of the depicted person?':\"subjectGender\",\n"," 'What is the age of the depicted person?':\"subjectAge\",\n"," 'Which state do you currently reside in?':\"annotator_state\",\n"," 'You are currently:':\"annotator_employment\",\n"," 'What is your educational level?': \"annotator_educationLevel\",\n"," 'What is your gender?': \"annotator_gender\",\n"," 'What is your race?': \"annotator_race\",\n"," 'What is your age?': \"annotator_age\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuxMPjCcK8h_"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWOnRGpRK8h_"},"source":["df_males=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7jPCl9oK8iA"},"source":["list(df_males.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEJWjHlZK8iA"},"source":["initial_df = pd.read_excel (r'/content/drive/MyDrive/allimages-male.xlsx')\n","print (initial_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsTpBV0lK8iA"},"source":["initial_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AOcIAKYK8iA"},"source":["list(initial_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kzII3AHK8iA"},"source":["listOfUsefulColumns=[\n"," 'author_id',\n"," 'ID',\n"," 'How attractive do you find this person?',\n"," 'How trustworthy do you find this person?',\n"," \"The person's race is:\",\n"," \"The person's skin color is:\",\n"," 'What is the gender of the depicted person?',\n"," 'What is the age of the depicted person?',\n"," 'Which state do you currently reside in?',\n"," 'You are currently:',\n"," 'What is your educational level?',\n"," 'What is your gender?',\n"," 'What is your race?',\n"," 'What is your age?']\n","df=initial_df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqHEclqZK8iA"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-Hin8eqK8iB"},"source":["df= df.rename(columns={\n","    'author_id':\"author_id\",\n"," 'ID':\"imageName\" ,\n"," 'How attractive do you find this person?': \"subjectAttractiveness\",\n"," 'How trustworthy do you find this person?': \"subjectTrustworthyness\",\n"," \"The person's race is:\": \"subjectEthicity\",\n"," \"The person's skin color is:\": \"subjectSkinColour\",\n"," 'What is the gender of the depicted person?':\"subjectGender\",\n"," 'What is the age of the depicted person?':\"subjectAge\",\n"," 'Which state do you currently reside in?':\"annotator_state\",\n"," 'You are currently:':\"annotator_employment\",\n"," 'What is your educational level?': \"annotator_educationLevel\",\n"," 'What is your gender?': \"annotator_gender\",\n"," 'What is your race?': \"annotator_race\",\n"," 'What is your age?': \"annotator_age\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xiz1hnrK8iB"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pHPh3YGK8iB"},"source":["df_female=df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yAJFc9yK8iC"},"source":["mergedDF=pd.concat([df_female, df_males], ignore_index=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tFhsH9RK8iC","executionInfo":{"status":"ok","timestamp":1626171646848,"user_tz":-60,"elapsed":50,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"39238532-1add-48f6-f7ae-11d5809f7e2e"},"source":["print(df_males.shape)\n","print(df_female.shape)\n","print(mergedDF.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(597, 14)\n","(597, 14)\n","(1194, 14)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"VFGO51_pK8iC","executionInfo":{"status":"ok","timestamp":1626171646849,"user_tz":-60,"elapsed":30,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"80bf2142-e61b-4b3d-a28e-2620cfec549b"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>imageName</th>\n","      <th>subjectAttractiveness</th>\n","      <th>subjectTrustworthyness</th>\n","      <th>subjectEthicity</th>\n","      <th>subjectSkinColour</th>\n","      <th>subjectGender</th>\n","      <th>subjectAge</th>\n","      <th>annotator_state</th>\n","      <th>annotator_employment</th>\n","      <th>annotator_educationLevel</th>\n","      <th>annotator_gender</th>\n","      <th>annotator_race</th>\n","      <th>annotator_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4881693</td>\n","      <td>AF-205</td>\n","      <td>4 - Neutral</td>\n","      <td>5 - Somewhat Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>24</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4770277</td>\n","      <td>AF-208</td>\n","      <td>5 - Somewhat Attractive</td>\n","      <td>5 - Somewhat Trustworthy</td>\n","      <td>Latino/a</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>27</td>\n","      <td>New Mexico</td>\n","      <td>Unemployed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>Asian</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4881693</td>\n","      <td>AF-249</td>\n","      <td>2 - Non Attractive</td>\n","      <td>3 - Somewhat non Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>22</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4881693</td>\n","      <td>AF-220</td>\n","      <td>2 - Non Attractive</td>\n","      <td>3 - Somewhat non Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>32</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4881693</td>\n","      <td>AF-235</td>\n","      <td>5 - Somewhat Attractive</td>\n","      <td>3 - Somewhat non Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>28</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4881693</td>\n","      <td>AF-227</td>\n","      <td>1 - Not at all Attractive</td>\n","      <td>3 - Somewhat non Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>27</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4881693</td>\n","      <td>AF-242</td>\n","      <td>3 - Somewhat non Attractive</td>\n","      <td>3 - Somewhat non Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>26</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4881693</td>\n","      <td>AF-234</td>\n","      <td>3 - Somewhat non Attractive</td>\n","      <td>6 - Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Medium</td>\n","      <td>Female</td>\n","      <td>23</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1781261</td>\n","      <td>AF-247</td>\n","      <td>5 - Somewhat Attractive</td>\n","      <td>4 - Neutral</td>\n","      <td>Asian</td>\n","      <td>Light</td>\n","      <td>Male</td>\n","      <td>25</td>\n","      <td>nc</td>\n","      <td>Retired</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4881693</td>\n","      <td>AF-256</td>\n","      <td>6 - Attractive</td>\n","      <td>6 - Trustworthy</td>\n","      <td>Asian</td>\n","      <td>Light</td>\n","      <td>Female</td>\n","      <td>28</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>Male</td>\n","      <td>White</td>\n","      <td>55</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   author_id imageName  ... annotator_race annotator_age\n","0    4881693    AF-205  ...          White            55\n","1    4770277    AF-208  ...          Asian            37\n","2    4881693    AF-249  ...          White            55\n","3    4881693    AF-220  ...          White            55\n","4    4881693    AF-235  ...          White            55\n","5    4881693    AF-227  ...          White            55\n","6    4881693    AF-242  ...          White            55\n","7    4881693    AF-234  ...          White            55\n","8    1781261    AF-247  ...          White            56\n","9    4881693    AF-256  ...          White            55\n","\n","[10 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":262}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mNHN8xrK8iC","executionInfo":{"status":"ok","timestamp":1626171646850,"user_tz":-60,"elapsed":30,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"0b2afb49-8a8f-4053-9f12-6c7785df0ffd"},"source":["list(np.unique(mergedDF[\"subjectAttractiveness\"]))\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"1 - Not at all Attractive\", 'subjectAttractiveness'] = 1\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"2 - Non Attractive\", 'subjectAttractiveness'] = 2\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"3 - Somewhat non Attractive\", 'subjectAttractiveness'] = 3\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"4 - Neutral\", 'subjectAttractiveness'] = 4\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"5 - Somewhat Attractive\", 'subjectAttractiveness'] = 5\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"6 - Attractive\", 'subjectAttractiveness'] = 6\n","mergedDF.loc[mergedDF[\"subjectAttractiveness\"]==\"7 - Extremely Attractive\", 'subjectAttractiveness'] = 7\n","\n","\n","list(np.unique(mergedDF[\"subjectAttractiveness\"]))\n","\n","\n","mergedDF.head(2)\n","list(np.unique(mergedDF[\"subjectTrustworthyness\"]))\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"1 - Not at all Trustworthy\", 'subjectTrustworthyness'] = 1\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"2 - Non Trustworthy\", 'subjectTrustworthyness'] = 2\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"3 - Somewhat non Trustworthy\", 'subjectTrustworthyness'] = 3\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"4 - Neutral\", 'subjectTrustworthyness'] = 4\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"5 - Somewhat Trustworthy\", 'subjectTrustworthyness'] = 5\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"6 - Trustworthy\", 'subjectTrustworthyness'] = 6\n","mergedDF.loc[mergedDF[\"subjectTrustworthyness\"]==\"7 - Extremely Trustworthy\", 'subjectTrustworthyness'] = 7\n","\n","\n","list(np.unique(mergedDF[\"subjectTrustworthyness\"]))\n","\n","mergedDF.head(2)\n","list(np.unique(mergedDF[\"subjectEthicity\"]))\n","mergedDF.loc[mergedDF[\"subjectEthicity\"]==\"Asian\", 'subjectEthicity'] = \"A\"\n","mergedDF.loc[mergedDF[\"subjectEthicity\"]==\"Black\", 'subjectEthicity'] = \"B\"\n","mergedDF.loc[mergedDF[\"subjectEthicity\"]==\"Latino/a\", 'subjectEthicity'] = \"L\"\n","mergedDF.loc[mergedDF[\"subjectEthicity\"]==\"White\", 'subjectEthicity'] = \"W\"\n","\n","\n","list(np.unique(mergedDF[\"subjectEthicity\"]))\n","\n","mergedDF.head(2)\n","targetColumn=\"subjectGender\"\n","list(np.unique(mergedDF[targetColumn]))\n","mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n","\n","list(np.unique(mergedDF[targetColumn]))\n","\n","targetColumn=\"annotator_gender\"\n","list(np.unique(mergedDF[targetColumn]))\n","mergedDF.loc[mergedDF[targetColumn]==\"Female\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Male\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Other\", targetColumn] = \"O\"\n","\n","\n","list(np.unique(mergedDF[targetColumn]))\n","\n","mergedDF.head(5)\n","targetColumn=\"annotator_race\"\n","list(np.unique(mergedDF[targetColumn]))\n","mergedDF.loc[mergedDF[targetColumn]==\"Asian\", targetColumn] = \"A\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Black\", targetColumn] = \"B\"\n","mergedDF.loc[mergedDF[targetColumn]==\"Latino/a\", targetColumn] = \"L\"\n","mergedDF.loc[mergedDF[targetColumn]==\"White\", targetColumn] = \"W\"\n","\n","\n","list(np.unique(mergedDF[targetColumn]))\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A', 'B', 'L', 'W']"]},"metadata":{"tags":[]},"execution_count":263}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"WmEcR5tJN0wr","executionInfo":{"status":"ok","timestamp":1626171646851,"user_tz":-60,"elapsed":12,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"1f56ebc8-9e24-4978-ca8b-c234c4c5aaa3"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>imageName</th>\n","      <th>subjectAttractiveness</th>\n","      <th>subjectTrustworthyness</th>\n","      <th>subjectEthicity</th>\n","      <th>subjectSkinColour</th>\n","      <th>subjectGender</th>\n","      <th>subjectAge</th>\n","      <th>annotator_state</th>\n","      <th>annotator_employment</th>\n","      <th>annotator_educationLevel</th>\n","      <th>annotator_gender</th>\n","      <th>annotator_race</th>\n","      <th>annotator_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4881693</td>\n","      <td>AF-205</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>24</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4770277</td>\n","      <td>AF-208</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>L</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27</td>\n","      <td>New Mexico</td>\n","      <td>Unemployed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4881693</td>\n","      <td>AF-249</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>22</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4881693</td>\n","      <td>AF-220</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>32</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4881693</td>\n","      <td>AF-235</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>28</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4881693</td>\n","      <td>AF-227</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4881693</td>\n","      <td>AF-242</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>26</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4881693</td>\n","      <td>AF-234</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>23</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1781261</td>\n","      <td>AF-247</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>B</td>\n","      <td>25</td>\n","      <td>nc</td>\n","      <td>Retired</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4881693</td>\n","      <td>AF-256</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>A</td>\n","      <td>28</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   author_id imageName  ... annotator_race annotator_age\n","0    4881693    AF-205  ...              W            55\n","1    4770277    AF-208  ...              A            37\n","2    4881693    AF-249  ...              W            55\n","3    4881693    AF-220  ...              W            55\n","4    4881693    AF-235  ...              W            55\n","5    4881693    AF-227  ...              W            55\n","6    4881693    AF-242  ...              W            55\n","7    4881693    AF-234  ...              W            55\n","8    1781261    AF-247  ...              W            56\n","9    4881693    AF-256  ...              W            55\n","\n","[10 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":264}]},{"cell_type":"code","metadata":{"id":"XvqNza8NK8iI"},"source":["def turnColumnsToFloat(givenDF):\n","  for column in givenDF.columns:\n","    try:\n","      givenDF[column]=givenDF[column].astype(np.float32)\n","    except: \n","      print(\"column \", column, \" is not a number \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CE-rZ1pFK8iI","executionInfo":{"status":"ok","timestamp":1626171647700,"user_tz":-60,"elapsed":24,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"745269d6-61ce-4a5d-c94a-0b5c3aaef624"},"source":["turnColumnsToFloat(mergedDF)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["column  imageName  is not a number \n","column  subjectEthicity  is not a number \n","column  subjectSkinColour  is not a number \n","column  subjectGender  is not a number \n","column  annotator_state  is not a number \n","column  annotator_employment  is not a number \n","column  annotator_educationLevel  is not a number \n","column  annotator_gender  is not a number \n","column  annotator_race  is not a number \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j7FMT-TrK8iI"},"source":["import random \n","def generateRandomNumber( minimum=0, maximum=10):\n","  return random.uniform(minimum, maximum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PlF1A4X0K8iI"},"source":["def pickAtRandom(lista):\n","  return random.choice(lista)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvHS3WOqK8iJ","executionInfo":{"status":"ok","timestamp":1626171648775,"user_tz":-60,"elapsed":24,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"ebf6e5e4-8026-4567-bf47-1aee0a941c9d"},"source":["generateRandomNumber()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.4169585450846078"]},"metadata":{"tags":[]},"execution_count":269}]},{"cell_type":"code","metadata":{"id":"HNBj1Vx3OKx7"},"source":["mergedDF[\"isRandom\"]=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"JcYUkUpjOPf7","executionInfo":{"status":"ok","timestamp":1626171649752,"user_tz":-60,"elapsed":543,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"f4324483-b023-4578-a118-607acad1d3b3"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>imageName</th>\n","      <th>subjectAttractiveness</th>\n","      <th>subjectTrustworthyness</th>\n","      <th>subjectEthicity</th>\n","      <th>subjectSkinColour</th>\n","      <th>subjectGender</th>\n","      <th>subjectAge</th>\n","      <th>annotator_state</th>\n","      <th>annotator_employment</th>\n","      <th>annotator_educationLevel</th>\n","      <th>annotator_gender</th>\n","      <th>annotator_race</th>\n","      <th>annotator_age</th>\n","      <th>isRandom</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4881693.0</td>\n","      <td>AF-205</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>24.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4770277.0</td>\n","      <td>AF-208</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>L</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27.0</td>\n","      <td>New Mexico</td>\n","      <td>Unemployed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>37.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4881693.0</td>\n","      <td>AF-249</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>22.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4881693.0</td>\n","      <td>AF-220</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>32.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4881693.0</td>\n","      <td>AF-235</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>28.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4881693.0</td>\n","      <td>AF-227</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4881693.0</td>\n","      <td>AF-242</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>26.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4881693.0</td>\n","      <td>AF-234</td>\n","      <td>3.0</td>\n","      <td>6.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>23.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1781261.0</td>\n","      <td>AF-247</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>B</td>\n","      <td>25.0</td>\n","      <td>nc</td>\n","      <td>Retired</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>56.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4881693.0</td>\n","      <td>AF-256</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>A</td>\n","      <td>28.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   author_id imageName  ...  annotator_age  isRandom\n","0  4881693.0    AF-205  ...           55.0     False\n","1  4770277.0    AF-208  ...           37.0     False\n","2  4881693.0    AF-249  ...           55.0     False\n","3  4881693.0    AF-220  ...           55.0     False\n","4  4881693.0    AF-235  ...           55.0     False\n","5  4881693.0    AF-227  ...           55.0     False\n","6  4881693.0    AF-242  ...           55.0     False\n","7  4881693.0    AF-234  ...           55.0     False\n","8  1781261.0    AF-247  ...           56.0     False\n","9  4881693.0    AF-256  ...           55.0     False\n","\n","[10 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":271}]},{"cell_type":"code","metadata":{"id":"hTgJ2zIaK8iJ"},"source":["randomDF= pd.DataFrame()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8udz35aK8iJ","executionInfo":{"status":"ok","timestamp":1626171649754,"user_tz":-60,"elapsed":25,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"c77bfb15-53a7-4992-9f0e-1feb343ef88c"},"source":["numberOfRows=df_female.shape[0]\n","\n","for column in df_female.columns:\n","  if(column== \"imageName\"):\n","    randomDF[column]=df_female[column]\n","  else:\n","    newColumn=column.split(\"female\")[0]\n","    print(newColumn)\n","    if (str(mergedDF.dtypes[column])==\"object\"):\n","      items= list(np.unique(mergedDF[column]))\n","      listOfItems=list()\n","      for index in range(numberOfRows):\n","        listOfItems.append(pickAtRandom(items)) \n","      randomDF[newColumn]=  listOfItems\n","    else: \n","      maximum=max(mergedDF[column])\n","      minimum= min(mergedDF[column])\n","      listOfNumbers=np.empty(shape=numberOfRows)\n","      for index in range(numberOfRows):\n","        listOfNumbers[index]=generateRandomNumber(maximum=maximum, minimum=minimum) \n","      randomDF[newColumn]=  listOfNumbers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["author_id\n","subjectAttractiveness\n","subjectTrustworthyness\n","subjectEthicity\n","subjectSkinColour\n","subjectGender\n","subjectAge\n","annotator_state\n","annotator_employment\n","annotator_educationLevel\n","annotator_gender\n","annotator_race\n","annotator_age\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UV_htv_GK8iJ","executionInfo":{"status":"ok","timestamp":1626171650536,"user_tz":-60,"elapsed":41,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"05f44078-c04d-44e7-cd47-5f6ff4cb04a6"},"source":["randomDF.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(597, 14)"]},"metadata":{"tags":[]},"execution_count":274}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDsPBAg2OW2T","executionInfo":{"status":"ok","timestamp":1626171650536,"user_tz":-60,"elapsed":22,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"aaac4f19-7044-4442-c50f-c708f65cc02c"},"source":["df_female.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(597, 14)"]},"metadata":{"tags":[]},"execution_count":275}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6ShNq6KK8iK","executionInfo":{"status":"ok","timestamp":1626171650904,"user_tz":-60,"elapsed":4,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"df6cebc5-a82b-4b08-da52-4094e0eb87f6"},"source":["mergedDF.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1194, 15)"]},"metadata":{"tags":[]},"execution_count":276}]},{"cell_type":"code","metadata":{"id":"X8UtnsYgK8iJ"},"source":["randomDF[\"isRandom\"]=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"dNZml0nbO4go","executionInfo":{"status":"ok","timestamp":1626171653731,"user_tz":-60,"elapsed":7,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"ab8e5341-8f83-4f52-fa46-49ff00d69f59"},"source":["randomDF.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>imageName</th>\n","      <th>subjectAttractiveness</th>\n","      <th>subjectTrustworthyness</th>\n","      <th>subjectEthicity</th>\n","      <th>subjectSkinColour</th>\n","      <th>subjectGender</th>\n","      <th>subjectAge</th>\n","      <th>annotator_state</th>\n","      <th>annotator_employment</th>\n","      <th>annotator_educationLevel</th>\n","      <th>annotator_gender</th>\n","      <th>annotator_race</th>\n","      <th>annotator_age</th>\n","      <th>isRandom</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.001207e+06</td>\n","      <td>AF-205</td>\n","      <td>5.235313</td>\n","      <td>5.850593</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>B</td>\n","      <td>82.105645</td>\n","      <td>Dallas</td>\n","      <td>Student</td>\n","      <td>High-school graduate</td>\n","      <td>O</td>\n","      <td>A</td>\n","      <td>100.801564</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.434364e+06</td>\n","      <td>AF-208</td>\n","      <td>1.284981</td>\n","      <td>5.442155</td>\n","      <td>L</td>\n","      <td>Dark</td>\n","      <td>B</td>\n","      <td>11.643488</td>\n","      <td>Us</td>\n","      <td>Unemployed</td>\n","      <td>Master or equivalent</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>53.046052</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.682277e+06</td>\n","      <td>AF-249</td>\n","      <td>1.777459</td>\n","      <td>4.567218</td>\n","      <td>W</td>\n","      <td>Dark</td>\n","      <td>B</td>\n","      <td>97.529202</td>\n","      <td>Watk</td>\n","      <td>Retired</td>\n","      <td>Bachelor or equivalent</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>102.914201</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6.398756e+06</td>\n","      <td>AF-220</td>\n","      <td>1.837934</td>\n","      <td>4.312968</td>\n","      <td>B</td>\n","      <td>Dark</td>\n","      <td>A</td>\n","      <td>48.891921</td>\n","      <td>Fl6</td>\n","      <td>Student</td>\n","      <td>Bachelor or equivalent</td>\n","      <td>B</td>\n","      <td>B</td>\n","      <td>80.001635</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.528220e+06</td>\n","      <td>AF-235</td>\n","      <td>4.707963</td>\n","      <td>3.898002</td>\n","      <td>B</td>\n","      <td>Medium</td>\n","      <td>O</td>\n","      <td>47.508716</td>\n","      <td>Washington</td>\n","      <td>Unemployed</td>\n","      <td>Master or equivalent</td>\n","      <td>O</td>\n","      <td>A</td>\n","      <td>158.220087</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5.590141e+06</td>\n","      <td>AF-227</td>\n","      <td>1.399940</td>\n","      <td>3.959163</td>\n","      <td>W</td>\n","      <td>Medium</td>\n","      <td>B</td>\n","      <td>48.378358</td>\n","      <td>Texax</td>\n","      <td>Student</td>\n","      <td>Master or equivalent</td>\n","      <td>O</td>\n","      <td>L</td>\n","      <td>266.591313</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5.073641e+06</td>\n","      <td>AF-242</td>\n","      <td>6.591034</td>\n","      <td>1.167569</td>\n","      <td>W</td>\n","      <td>Dark</td>\n","      <td>O</td>\n","      <td>81.123198</td>\n","      <td>Ww</td>\n","      <td>Student</td>\n","      <td>Bachelor or equivalent</td>\n","      <td>O</td>\n","      <td>B</td>\n","      <td>375.382416</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6.078553e+06</td>\n","      <td>AF-234</td>\n","      <td>2.336288</td>\n","      <td>5.336252</td>\n","      <td>B</td>\n","      <td>Medium</td>\n","      <td>O</td>\n","      <td>54.219157</td>\n","      <td>Job</td>\n","      <td>Student</td>\n","      <td>Master or equivalent</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>177.771563</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2.598445e+06</td>\n","      <td>AF-247</td>\n","      <td>4.807040</td>\n","      <td>6.526866</td>\n","      <td>A</td>\n","      <td>Dark</td>\n","      <td>B</td>\n","      <td>59.715544</td>\n","      <td>Washington</td>\n","      <td>Employed for wages</td>\n","      <td>Bachelor or equivalent</td>\n","      <td>O</td>\n","      <td>A</td>\n","      <td>247.157300</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4.391821e+06</td>\n","      <td>AF-256</td>\n","      <td>5.081825</td>\n","      <td>6.336339</td>\n","      <td>W</td>\n","      <td>Light</td>\n","      <td>B</td>\n","      <td>96.799305</td>\n","      <td>Good man</td>\n","      <td>Retired</td>\n","      <td>Bachelor or equivalent</td>\n","      <td>A</td>\n","      <td>W</td>\n","      <td>141.096363</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      author_id imageName  ...  annotator_age  isRandom\n","0  5.001207e+06    AF-205  ...     100.801564      True\n","1  3.434364e+06    AF-208  ...      53.046052      True\n","2  5.682277e+06    AF-249  ...     102.914201      True\n","3  6.398756e+06    AF-220  ...      80.001635      True\n","4  4.528220e+06    AF-235  ...     158.220087      True\n","5  5.590141e+06    AF-227  ...     266.591313      True\n","6  5.073641e+06    AF-242  ...     375.382416      True\n","7  6.078553e+06    AF-234  ...     177.771563      True\n","8  2.598445e+06    AF-247  ...     247.157300      True\n","9  4.391821e+06    AF-256  ...     141.096363      True\n","\n","[10 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":278}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVNGyaYLO4mL","executionInfo":{"status":"ok","timestamp":1626171654823,"user_tz":-60,"elapsed":4,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"9151325a-218c-4631-ecfb-1ffe66f6b271"},"source":["mergedDF=pd.concat([mergedDF, randomDF], ignore_index=True)\n","mergedDF.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1791, 15)"]},"metadata":{"tags":[]},"execution_count":279}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"LspCw3RoK8iK","executionInfo":{"status":"ok","timestamp":1626171657001,"user_tz":-60,"elapsed":381,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"119a65c1-5ed9-4316-97e4-7de70cd5d160"},"source":["mergedDF.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author_id</th>\n","      <th>imageName</th>\n","      <th>subjectAttractiveness</th>\n","      <th>subjectTrustworthyness</th>\n","      <th>subjectEthicity</th>\n","      <th>subjectSkinColour</th>\n","      <th>subjectGender</th>\n","      <th>subjectAge</th>\n","      <th>annotator_state</th>\n","      <th>annotator_employment</th>\n","      <th>annotator_educationLevel</th>\n","      <th>annotator_gender</th>\n","      <th>annotator_race</th>\n","      <th>annotator_age</th>\n","      <th>isRandom</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4881693.0</td>\n","      <td>AF-205</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>24.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4770277.0</td>\n","      <td>AF-208</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>L</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27.0</td>\n","      <td>New Mexico</td>\n","      <td>Unemployed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>37.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4881693.0</td>\n","      <td>AF-249</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>22.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4881693.0</td>\n","      <td>AF-220</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>32.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4881693.0</td>\n","      <td>AF-235</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>28.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4881693.0</td>\n","      <td>AF-227</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>27.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4881693.0</td>\n","      <td>AF-242</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>26.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4881693.0</td>\n","      <td>AF-234</td>\n","      <td>3.0</td>\n","      <td>6.0</td>\n","      <td>A</td>\n","      <td>Medium</td>\n","      <td>A</td>\n","      <td>23.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1781261.0</td>\n","      <td>AF-247</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>B</td>\n","      <td>25.0</td>\n","      <td>nc</td>\n","      <td>Retired</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>56.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4881693.0</td>\n","      <td>AF-256</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>A</td>\n","      <td>Light</td>\n","      <td>A</td>\n","      <td>28.0</td>\n","      <td>California</td>\n","      <td>Self-employed</td>\n","      <td>High-school graduate</td>\n","      <td>B</td>\n","      <td>W</td>\n","      <td>55.0</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   author_id imageName  ...  annotator_age  isRandom\n","0  4881693.0    AF-205  ...           55.0     False\n","1  4770277.0    AF-208  ...           37.0     False\n","2  4881693.0    AF-249  ...           55.0     False\n","3  4881693.0    AF-220  ...           55.0     False\n","4  4881693.0    AF-235  ...           55.0     False\n","5  4881693.0    AF-227  ...           55.0     False\n","6  4881693.0    AF-242  ...           55.0     False\n","7  4881693.0    AF-234  ...           55.0     False\n","8  1781261.0    AF-247  ...           56.0     False\n","9  4881693.0    AF-256  ...           55.0     False\n","\n","[10 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":280}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdOO8YoDX7aJ","executionInfo":{"status":"ok","timestamp":1626171658472,"user_tz":-60,"elapsed":6,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"e0b800e7-0cdf-4dac-8e0b-fdaeb53bc2ac"},"source":["mergedDF.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['author_id', 'imageName', 'subjectAttractiveness',\n","       'subjectTrustworthyness', 'subjectEthicity', 'subjectSkinColour',\n","       'subjectGender', 'subjectAge', 'annotator_state',\n","       'annotator_employment', 'annotator_educationLevel', 'annotator_gender',\n","       'annotator_race', 'annotator_age', 'isRandom'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":281}]},{"cell_type":"code","metadata":{"id":"-1AySMq0X-EE"},"source":["mergedDF= mergedDF.rename(columns={\"imageName\":\"Model\" })"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsDNYUfKYYB8","executionInfo":{"status":"ok","timestamp":1626171661614,"user_tz":-60,"elapsed":3,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"3d813f08-5b65-4512-dbef-ae12a8b72af1"},"source":["mergedDF.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['author_id', 'Model', 'subjectAttractiveness', 'subjectTrustworthyness',\n","       'subjectEthicity', 'subjectSkinColour', 'subjectGender', 'subjectAge',\n","       'annotator_state', 'annotator_employment', 'annotator_educationLevel',\n","       'annotator_gender', 'annotator_race', 'annotator_age', 'isRandom'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":283}]},{"cell_type":"code","metadata":{"id":"-K6XTsJ7Qb1g"},"source":["df = pd.read_csv (r'/content/drive/MyDrive/final_train_dataset.csv')\n","test_df=pd.read_csv (r'/content/drive/MyDrive/final_test_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWDAXCl3Qx6d"},"source":["list(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HpgdYTMQyAJ"},"source":["listOfUsefulColumns=[\n"," 'id',\n"," 'Model',\n"," 'EthnicitySelf',\n"," 'GenderSelf',\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian',\n"," 'augm_type',\n"," 'cutFaceNet',\n"," 'cutvggface',\n"," 'cutOpenFace',\n"," 'cutDeepFace',\n"," 'cutDeepId',\n"," 'cutArcFace',\n"," 'facenet',\n"," 'vggface',\n"," 'openface',\n"," 'deepface',\n"," 'deepID',\n"," 'arcFace']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQDPkAW9Q5ZB"},"source":["df=df[listOfUsefulColumns]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84TO8fLdSaT1"},"source":["list(test_df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4H7clXRSYzw"},"source":["listOfUsefulColumns=[\n"," 'id',\n"," 'Model',\n"," 'EthnicitySelf',\n"," 'GenderSelf',\n"," 'AgeSelf',\n"," 'AgeRated',\n"," 'FemaleProb',\n"," 'MaleProb',\n"," 'AsianProb',\n"," 'ChineseAsianProb',\n"," 'JapaneseAsianProb',\n"," 'IndianAsianProb',\n"," 'OtherAsianProb',\n"," 'MiddleEasternProb',\n"," 'BlackProb',\n"," 'LatinoProb',\n"," 'MultiProb',\n"," 'OtherProb',\n"," 'WhiteProb',\n"," 'Afraid',\n"," 'Angry',\n"," 'Attractive',\n"," 'Babyfaced',\n"," 'Disgusted',\n"," 'Dominant',\n"," 'Feminine',\n"," 'Happy',\n"," 'Masculine',\n"," 'Prototypic',\n"," 'Sad',\n"," 'Surprised',\n"," 'Threatening',\n"," 'Trustworthy',\n"," 'Unusual',\n"," 'Warm',\n"," 'Competent',\n"," 'SocialStatus',\n"," 'LuminanceMedian',\n"," 'image',\n"," 'facenet',\n"," 'vggface',\n"," 'openface',\n"," 'deepface',\n"," 'deepID',\n"," 'arcFace',\n"," 'cutFaceNet',\n"," 'cutvggface',\n"," 'cutOpenFace',\n"," 'cutDeepFace',\n"," 'cutDeepId',\n"," 'cutArcFace']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_Vd3lF5Q_WQ"},"source":["test_df=test_df[listOfUsefulColumns]\n","test_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O322G-IlY83l","executionInfo":{"status":"ok","timestamp":1626171777896,"user_tz":-60,"elapsed":357,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"c85a0a9e-34bf-491a-91d0-329a3b98ab82"},"source":["print(df.shape)\n","print(test_df.shape)\n","print(mergedDF.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3336, 51)\n","(180, 51)\n","(1791, 15)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w12CY2IhX5p5"},"source":["df=pd.merge(mergedDF,df,on='Model')\n","test_df=pd.merge(mergedDF,test_df,on='Model')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyBumIiNZEW9","executionInfo":{"status":"ok","timestamp":1626172438263,"user_tz":-60,"elapsed":316,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"1935a522-930a-4c18-8084-d0ad35835ee5"},"source":["print(df.shape)\n","print(test_df.shape)\n","print(mergedDF.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10008, 65)\n","(540, 65)\n","(1791, 15)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"90qYOtdybkOw"},"source":["df.to_csv('/content/drive/MyDrive/final_train_dataset.csv')\n","test_df.to_csv('/content/drive/MyDrive/final_test_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY6o4N8KTk3m"},"source":["def getStratifiedDF(df,targetColumn ):\n","  #use stratfied samplying\n","  sizeOfSampleFromEachClass=min(df.groupby(targetColumn).size())\n","  # sizeOfSampleFromEachClass=10\n","  stradifiedSampleDF=df.groupby(targetColumn, group_keys=False).apply(lambda x: x.sample(min(len(x), sizeOfSampleFromEachClass)))\n","  stradifiedSampleDF=stradifiedSampleDF.copy()\n","  print(stradifiedSampleDF.groupby(targetColumn).size())\n","  return stradifiedSampleDF\n","  # stradifiedSampleDF=oringinalDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gev2fyQEZb1J","executionInfo":{"status":"ok","timestamp":1626171889485,"user_tz":-60,"elapsed":315,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"aae7c2bf-4ced-4ac4-f633-ab857a54a60c"},"source":["mergedDF.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['author_id', 'Model', 'subjectAttractiveness', 'subjectTrustworthyness',\n","       'subjectEthicity', 'subjectSkinColour', 'subjectGender', 'subjectAge',\n","       'annotator_state', 'annotator_employment', 'annotator_educationLevel',\n","       'annotator_gender', 'annotator_race', 'annotator_age', 'isRandom'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":293}]},{"cell_type":"code","metadata":{"id":"vgZl8zUNZ0Lv"},"source":["# dont paris sto alo\n","\n","isClassificationDict={\"AgeRated\":False, \n","                      \"Trustworthy\":False, \n","                      \"Attractive\":False, \n","                      \"GenderSelf\":True, \n","                      \"EthnicitySelf\":True}\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# define example\n","# data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n","def returnOneHotEncodedVersion(values):\n","  # integer encode\n","  label_encoder = LabelEncoder()\n","  integer_encoded = label_encoder.fit_transform(values)\n","  # binary encode\n","  onehot_encoder = OneHotEncoder(sparse=False)\n","  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","  onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","  return onehot_encoded"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1Iumpu_XAnp"},"source":["originalToAnnotatorsColumnMapping={\"AgeRated\":\"subjectAge\" ,\"Trustworthy\":\"subjectTrustworthyness\",\n","                                   \"Attractive\":\"subjectAttractiveness\", \"GenderSelf\":\"subjectGender\",\n","                                   \"EthnicitySelf\": \"subjectEthicity\"} \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgtnUyRzTGtf"},"source":["\n","def getLabelsByGroup(df, testDF, groupName, targetColumn):\n","  #1 stratified samplying df\n","  stratifiedDF=getStratifiedDF(df,groupName )\n","  stratifiedTestDF=getStratifiedDF(testDF,groupName )\n","  # find unique values \n","  uniqueValues = list(np.unique(stratifiedDF[groupName]))\n","  # create a df using only that unique values\n","  allLabelTupples=list()\n","  for uvalue in uniqueValues:\n","    currentDF= stratifiedDF[stratifiedDF[groupName]==uvalue]\n","    currentTestDF= stratifiedTestDF[stratifiedTestDF[groupName]==uvalue]\n","    print(list(np.unique(currentDF[groupName])))\n","    if(isClassificationDict[targetColumn]==True):\n","      stratified_df=getStratifiedDF(currentDF,targetColumn=targetColumn )\n","      stratified_test_df=getStratifiedDF(currentTestDF,targetColumn=targetColumn )\n","\n","      trainLabels=returnOneHotEncodedVersion(list(stratified_df[targetColumn]))\n","      testLabels=returnOneHotEncodedVersion(list(stratified_test_df[targetColumn]))\n","    else:\n","      trainLabels=np.asarray(list(currentDF[targetColumn]))\n","      testLabels=np.asarray(list(currentTestDF[targetColumn]))\n","    allLabelTupples.append(((trainLabels, testLabels),str(uvalue) ))\n","  # for each df get labels\n","  return allLabelTupples "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zuf1WTFaRL7"},"source":["def getFirstOfEach(somthingDF):\n","  return somthingDF.iloc[0]\n","\n","def getCFDLabelsForTarget(df, testDF, targetColumn):\n","  idColumn=\"id\"\n","  tempDF=df.groupby(df[idColumn]).apply(getFirstOfEach)\n","  tempTestDF=testDF.groupby(testDF[idColumn]).apply(getFirstOfEach)\n","  if(isClassificationDict[targetColumn]==True):\n","      stratified_df=getStratifiedDF(tempDF,targetColumn=targetColumn )\n","      stratified_test_df=getStratifiedDF(tempTestDF,targetColumn=targetColumn )\n","\n","      trainLabels=returnOneHotEncodedVersion(list(stratified_df[targetColumn]))\n","      testLabels=returnOneHotEncodedVersion(list(stratified_test_df[targetColumn]))\n","  else:\n","    trainLabels=np.asarray(list(tempDF[targetColumn]))\n","    testLabels=np.asarray(list(tempTestDF[targetColumn]))\n","  \n","  return ((trainLabels, testLabels) , \"CFD\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lw7hOZLqSoY0"},"source":["def getLabelsForTarget(df, testDF, groupName, targetColumn):\n","  CFDLabels=getCFDLabelsForTarget(df, testDF, targetColumn)\n","  listOfAllTupples=[CFDLabels]\n","  listOfAllTupples= listOfAllTupples+ getLabelsByGroup(df, testDF, groupName, targetColumn)\n","  return listOfAllTupples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lODCdXPZTG6","executionInfo":{"status":"ok","timestamp":1626176331309,"user_tz":-60,"elapsed":2273,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"689bb020-da8d-44ed-f6ed-d28d25b10b5b"},"source":[" temp= getLabelsForTarget(df, test_df, groupName=\"annotator_gender\" , targetColumn=\"Trustworthy\")\n"," print(\"\\n\\n\\n\\n\\n\", len(temp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["annotator_gender\n","A    1064\n","B    1064\n","O    1064\n","dtype: int64\n","annotator_gender\n","A    66\n","B    66\n","O    66\n","dtype: int64\n","['A']\n","['B']\n","['O']\n","\n","\n","\n","\n","\n"," 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"R6SIMse7qKN3","executionInfo":{"status":"ok","timestamp":1626176347666,"user_tz":-60,"elapsed":357,"user":{"displayName":"Stylianos Herodotou","photoUrl":"","userId":"11396829892484379326"}},"outputId":"a7ba3ef5-da68-4e45-81f2-79187fe08ffa"},"source":["temp[3][1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'O'"]},"metadata":{"tags":[]},"execution_count":377}]},{"cell_type":"code","metadata":{"id":"iK_NmQxTQb1h"},"source":["df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6QPe23sQb1i"},"source":["mergedDF= mergedDF.rename(columns={\n"," 'imageName':\"Model\"\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gePLW47Qb1c"},"source":["mergedDF=pd.merge(mergedDF,randomDF,on='imageName')\n"],"execution_count":null,"outputs":[]}]}